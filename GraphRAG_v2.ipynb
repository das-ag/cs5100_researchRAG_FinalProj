{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation with LlamaIndex - V2\n",
    "\n",
    "[GraphRAG (Graphs + Retrieval Augmented Generation)](https://www.microsoft.com/en-us/research/project/graphrag/) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
    "\n",
    "This notebook provides guidance on constructing the GraphRAG pipeline using the LlamaIndex PropertyGraph abstractions using Neo4J.\n",
    "\n",
    "This notebook updates the GraphRAG pipeline to v2. If you havenâ€™t checked v1 yet, you can find it [here](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb). Following are the updates to the existing implementation:\n",
    "\n",
    "1. Integrate with Neo4J Graph database.\n",
    "2. Embedding based retrieval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "`graspologic` is used to use hierarchical_leiden for building communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-graph-stores-neo4j graspologic numpy==1.24.4 scipy==1.12.0 future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will use a sample news article dataset retrieved from Diffbot, which Tomaz has conveniently made available on GitHub for easy access.\n",
    "\n",
    "The dataset contains 2,500 samples; for ease of experimentation, we will use 50 of these samples, which include the `title` and `text` of news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801.0341</td>\n",
       "      <td>Michael Chertkov</td>\n",
       "      <td>Michael Chertkov (Los Alamos)</td>\n",
       "      <td>Exactness of Belief Propagation for Some Graph...</td>\n",
       "      <td>12 pages, 1 figure, submitted to JSTAT</td>\n",
       "      <td>J. Stat. Mech. (2008) P10016</td>\n",
       "      <td>10.1088/1742-5468/2008/10/P10016</td>\n",
       "      <td>LANL LA-UR-07-8441</td>\n",
       "      <td>cond-mat.stat-mech cond-mat.other cs.AI cs.IT ...</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>It is well known that an arbitrary graphical m...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Wed, 2 Jan 2008...</td>\n",
       "      <td>2009-11-13</td>\n",
       "      <td>[[Chertkov, Michael, , Los Alamos]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>803.4355</td>\n",
       "      <td>Marko A. Rodriguez</td>\n",
       "      <td>Marko A. Rodriguez</td>\n",
       "      <td>Grammar-Based Random Walkers in Semantic Networks</td>\n",
       "      <td>First draft of manuscript originally written i...</td>\n",
       "      <td>Rodriguez, M.A., \"Grammar-Based Random Walkers...</td>\n",
       "      <td>10.1016/j.knosys.2008.03.030</td>\n",
       "      <td>LA-UR-06-7791</td>\n",
       "      <td>cs.AI cs.DS</td>\n",
       "      <td>http://creativecommons.org/licenses/publicdomain/</td>\n",
       "      <td>Semantic networks qualify the meaning of an ed...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 31 Mar 200...</td>\n",
       "      <td>2008-09-11</td>\n",
       "      <td>[[Rodriguez, Marko A., ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810.2434</td>\n",
       "      <td>Edward Rosten</td>\n",
       "      <td>Edward Rosten, Reid Porter, Tom Drummond</td>\n",
       "      <td>Faster and better: a machine learning approach...</td>\n",
       "      <td>35 pages, 11 figures</td>\n",
       "      <td>IEEE Trans. PAMI, 32 (2010), 105--119</td>\n",
       "      <td>10.1109/TPAMI.2008.275</td>\n",
       "      <td>07-3912</td>\n",
       "      <td>cs.CV cs.LG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>The repeatability and efficiency of a corner d...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 14 Oct 200...</td>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>[[Rosten, Edward, ], [Porter, Reid, ], [Drummo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>812.4446</td>\n",
       "      <td>Peter Turney</td>\n",
       "      <td>Peter D. Turney (National Research Council of ...</td>\n",
       "      <td>The Latent Relation Mapping Engine: Algorithm ...</td>\n",
       "      <td>related work available at http://purl.org/pete...</td>\n",
       "      <td>Journal of Artificial Intelligence Research, (...</td>\n",
       "      <td>10.1613/jair.2693</td>\n",
       "      <td>NRC-50738</td>\n",
       "      <td>cs.CL cs.AI cs.LG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Many AI researchers and cognitive scientists h...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Tue, 23 Dec 200...</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>[[Turney, Peter D., , National Research Counci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901.3574</td>\n",
       "      <td>Christoph Benzmueller</td>\n",
       "      <td>Christoph Benzmueller</td>\n",
       "      <td>Automating Access Control Logics in Simple Typ...</td>\n",
       "      <td>ii + 20 pages</td>\n",
       "      <td>SEKI Report SR-2008-01 (ISSN 1437-4447), Saarl...</td>\n",
       "      <td>10.1007/978-3-642-01244-0_34</td>\n",
       "      <td>SEKI Report SR-2008-01</td>\n",
       "      <td>cs.LO cs.AI</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Garg and Abadi recently proved that prominent ...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Fri, 23 Jan 200...</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>[[Benzmueller, Christoph, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              submitter  \\\n",
       "0  801.0341       Michael Chertkov   \n",
       "1  803.4355     Marko A. Rodriguez   \n",
       "2  810.2434          Edward Rosten   \n",
       "3  812.4446           Peter Turney   \n",
       "4  901.3574  Christoph Benzmueller   \n",
       "\n",
       "                                             authors  \\\n",
       "0                      Michael Chertkov (Los Alamos)   \n",
       "1                                 Marko A. Rodriguez   \n",
       "2           Edward Rosten, Reid Porter, Tom Drummond   \n",
       "3  Peter D. Turney (National Research Council of ...   \n",
       "4                              Christoph Benzmueller   \n",
       "\n",
       "                                               title  \\\n",
       "0  Exactness of Belief Propagation for Some Graph...   \n",
       "1  Grammar-Based Random Walkers in Semantic Networks   \n",
       "2  Faster and better: a machine learning approach...   \n",
       "3  The Latent Relation Mapping Engine: Algorithm ...   \n",
       "4  Automating Access Control Logics in Simple Typ...   \n",
       "\n",
       "                                            comments  \\\n",
       "0             12 pages, 1 figure, submitted to JSTAT   \n",
       "1  First draft of manuscript originally written i...   \n",
       "2                               35 pages, 11 figures   \n",
       "3  related work available at http://purl.org/pete...   \n",
       "4                                      ii + 20 pages   \n",
       "\n",
       "                                         journal-ref  \\\n",
       "0                       J. Stat. Mech. (2008) P10016   \n",
       "1  Rodriguez, M.A., \"Grammar-Based Random Walkers...   \n",
       "2              IEEE Trans. PAMI, 32 (2010), 105--119   \n",
       "3  Journal of Artificial Intelligence Research, (...   \n",
       "4  SEKI Report SR-2008-01 (ISSN 1437-4447), Saarl...   \n",
       "\n",
       "                                doi               report-no  \\\n",
       "0  10.1088/1742-5468/2008/10/P10016      LANL LA-UR-07-8441   \n",
       "1      10.1016/j.knosys.2008.03.030           LA-UR-06-7791   \n",
       "2            10.1109/TPAMI.2008.275                 07-3912   \n",
       "3                 10.1613/jair.2693               NRC-50738   \n",
       "4      10.1007/978-3-642-01244-0_34  SEKI Report SR-2008-01   \n",
       "\n",
       "                                          categories  \\\n",
       "0  cond-mat.stat-mech cond-mat.other cs.AI cs.IT ...   \n",
       "1                                        cs.AI cs.DS   \n",
       "2                                        cs.CV cs.LG   \n",
       "3                                  cs.CL cs.AI cs.LG   \n",
       "4                                        cs.LO cs.AI   \n",
       "\n",
       "                                             license  \\\n",
       "0  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "1  http://creativecommons.org/licenses/publicdomain/   \n",
       "2  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "3  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "4  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  It is well known that an arbitrary graphical m...   \n",
       "1  Semantic networks qualify the meaning of an ed...   \n",
       "2  The repeatability and efficiency of a corner d...   \n",
       "3  Many AI researchers and cognitive scientists h...   \n",
       "4  Garg and Abadi recently proved that prominent ...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Wed, 2 Jan 2008...  2009-11-13   \n",
       "1  [{'version': 'v1', 'created': 'Mon, 31 Mar 200...  2008-09-11   \n",
       "2  [{'version': 'v1', 'created': 'Tue, 14 Oct 200...  2010-07-09   \n",
       "3  [{'version': 'v1', 'created': 'Tue, 23 Dec 200...  2020-08-20   \n",
       "4  [{'version': 'v1', 'created': 'Fri, 23 Jan 200...  2015-05-13   \n",
       "\n",
       "                                      authors_parsed  \n",
       "0                [[Chertkov, Michael, , Los Alamos]]  \n",
       "1                          [[Rodriguez, Marko A., ]]  \n",
       "2  [[Rosten, Edward, ], [Porter, Reid, ], [Drummo...  \n",
       "3  [[Turney, Peter D., , National Research Counci...  \n",
       "4                       [[Benzmueller, Christoph, ]]  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document\n",
    "\n",
    "json_path =  \"datasets/arxiv_cs_metadata.json\"\n",
    "nrows = 5\n",
    "papers = pd.read_json(json_path, lines=True, nrows=nrows)\n",
    "\n",
    "# papers = pd.read_csv(\n",
    "#     \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\"\n",
    "# )[:50]\n",
    "\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare documents as required by LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(text=f\"{row['title']}: {row['abstract']}\",)\n",
    "    for i, row in papers.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API Key and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-..\"\n",
    "\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"qwen2.5\",  request_timeout=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGExtractor\n",
    "\n",
    "The GraphRAGExtractor class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
    "\n",
    "This functionality is similar to that of the `SimpleLLMPathExtractor`, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing [extractors](https://docs.llamaindex.ai/en/latest/examples/property_graph/Dynamic_KG_Extraction/?h=comparing).\n",
    "\n",
    "Here's a breakdown of its functionality:\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. `llm:` The language model used for extraction.\n",
    "2. `extract_prompt:` A prompt template used to guide the LLM in extracting information.\n",
    "3. `parse_fn:` A function to parse the LLM's output into structured data.\n",
    "4. `max_paths_per_chunk:` Limits the number of triples extracted per text chunk.\n",
    "5. `num_workers:` For parallel processing of multiple text nodes.\n",
    "\n",
    "\n",
    "**Main Methods:**\n",
    "\n",
    "1. `__call__:` The entry point for processing a list of text nodes.\n",
    "2. `acall:` An asynchronous version of __call__ for improved performance.\n",
    "3. `_aextract:` The core method that processes each individual node.\n",
    "\n",
    "\n",
    "**Extraction Process:**\n",
    "\n",
    "For each input node (chunk of text):\n",
    "1. It sends the text to the LLM along with the extraction prompt.\n",
    "2. The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
    "3. Entities are converted into EntityNode objects. Entity description is stored in metadata\n",
    "4. Relationships are converted into Relation objects. Relationship description is stored in metadata.\n",
    "5. These are added to the node's metadata under KG_NODES_KEY and KG_RELATIONS_KEY.\n",
    "\n",
    "**NOTE:** In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = llm,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            print(f\"llm_response: {llm_response}\")\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            entity_metadata[\"entity_description\"] = description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGStore\n",
    "\n",
    "The `GraphRAGStore` class is an extension of the `Neo4jPropertyGraphStore`class, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
    "\n",
    "\n",
    "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`build_communities():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph.\n",
    "\n",
    "2. Applies the hierarchical Leiden algorithm for community detection.\n",
    "\n",
    "3. Collects detailed information about each community.\n",
    "\n",
    "4. Generates summaries for each community.\n",
    "\n",
    "`generate_community_summary(text):`\n",
    "\n",
    "1. Uses LLM to generate a summary of the relationships in a community.\n",
    "2. The summary includes entity names and a synthesis of relationship descriptions.\n",
    "\n",
    "`_create_nx_graph():`\n",
    "\n",
    "1. Converts the internal graph representation to a NetworkX graph for community detection.\n",
    "\n",
    "`_collect_community_info(nx_graph, clusters):`\n",
    "\n",
    "1. Collects detailed information about each node based on its community.\n",
    "2. Creates a string representation of each relationship within a community.\n",
    "\n",
    "`_summarize_communities(community_info):`\n",
    "\n",
    "1. Generates and stores summaries for each community using LLM.\n",
    "\n",
    "`get_community_summaries():`\n",
    "\n",
    "1. Returns the community summaries by building them if not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from collections import defaultdict\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "\n",
    "class GraphRAGStore(Neo4jPropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    entity_info = None\n",
    "    max_cluster_size = 5\n",
    "    llm = llm\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
    "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
    "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
    "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
    "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
    "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = llm.chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        self.entity_info, community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            if relation.properties[\"relationship_description\"] is None:\n",
    "                relation.properties[\"relationship_description\"] = \"\"\n",
    "            nx_graph.add_node(entity1.name)\n",
    "            nx_graph.add_node(entity2.name)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"\n",
    "        Collect information for each node based on their community,\n",
    "        allowing entities to belong to multiple clusters.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity_info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphRAGQueryEngine\n",
    "\n",
    "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
    "\n",
    "**Main Components:**\n",
    "\n",
    "`graph_store:` An instance of GraphRAGStore, which contains the community summaries.\n",
    "`llm:` A Language Model (LLM) used for generating and aggregating answers.\n",
    "\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "`custom_query(query_str: str)`\n",
    "\n",
    "1. This is the main entry point for processing a query. It retrieves community summaries, generates answers from each summary, and then aggregates these answers into a final response.\n",
    "\n",
    "`generate_answer_from_summary(community_summary, query):`\n",
    "\n",
    "1. Generates an answer for the query based on a single community summary.\n",
    "Uses the LLM to interpret the community summary in the context of the query.\n",
    "\n",
    "`aggregate_answers(community_answers):`\n",
    "\n",
    "1. Combines individual answers from different communities into a coherent final response.\n",
    "2. Uses the LLM to synthesize multiple perspectives into a single, concise answer.\n",
    "\n",
    "\n",
    "**Query Processing Flow:**\n",
    "\n",
    "1. Retrieve community summaries from the graph store.\n",
    "2. For each community summary, generate a specific answer to the query.\n",
    "3. Aggregate all community-specific answers into a final, coherent response.\n",
    "\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```\n",
    "query_engine = GraphRAGQueryEngine(graph_store=graph_store, llm=llm)\n",
    "\n",
    "response = query_engine.query(\"query\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM = llm\n",
    "    similarity_top_k: int = 20\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "\n",
    "        entities = self.get_entities(query_str, self.similarity_top_k)\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            self.graph_store.entity_info, entities\n",
    "        )\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for id, community_summary in community_summaries.items()\n",
    "            if id in community_ids\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def get_entities(self, query_str, similarity_top_k):\n",
    "        nodes_retrieved = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        enitites = set()\n",
    "        pattern = (\n",
    "            r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    "        )\n",
    "\n",
    "        for node in nodes_retrieved:\n",
    "            matches = re.findall(\n",
    "                pattern, node.text, re.MULTILINE | re.IGNORECASE\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                enitites.add(subject)\n",
    "                enitites.add(obj)\n",
    "\n",
    "        return list(enitites)\n",
    "\n",
    "    def retrieve_entity_communities(self, entity_info, entities):\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "        entity_info (dict): Dictionary mapping entities to their cluster IDs (list).\n",
    "        entities (list): List of entity names to retrieve information for.\n",
    "\n",
    "        Returns:\n",
    "        List of community or cluster IDs to which an entity belongs.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build End to End GraphRAG Pipeline\n",
    "\n",
    "Now that we have defined all the necessary components, letâ€™s construct the GraphRAG pipeline:\n",
    "\n",
    "1. Create nodes/chunks from the text.\n",
    "2. Build a PropertyGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`.\n",
    "3. Construct communities and generate a summary for each community using the graph built above.\n",
    "4. Create a `GraphRAGQueryEngine` and begin querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes/ chunks from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ProperGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\"$$$$<entity_name>$$$$<entity_type>$$$$<entity_description>)\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "\n",
    "Format each relationship as (\"relationship\"$$$$<source_entity>$$$$<target_entity>$$$$<relation>$$$$<relationship_description>)\n",
    "\n",
    "3. When finished, output.\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_pattern = r'\\(\"entity\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    "relationship_pattern = r'\\(\"relationship\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    "from llama_index.core.indices.property_graph import DynamicLLMPathExtractor\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    entities = re.findall(entity_pattern, response_str)\n",
    "    relationships = re.findall(relationship_pattern, response_str)\n",
    "    print(f\"response_str: {response_str}\")\n",
    "    print(f\"entities: {entities}\")\n",
    "    print(f\"relationships: {relationships}\")\n",
    "    if entities == []:\n",
    "        entities = [(\"DummyE\", \"DummyE\", \"DummyE\",)]\n",
    "    if relationships == []:\n",
    "        relationships = [(\"DummyR\", \"DummyR\", \"DummyR\", \"DummyR\")]\n",
    "    return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    parse_fn=parse_fn,\n",
    "\n",
    ")\n",
    "# max_triplets_per_chunk=20,\n",
    "#         num_workers=4\n",
    "# kg_extractor = DynamicLLMPathExtractor(\n",
    "#             llm=llm,\n",
    "#             max_triplets_per_chunk=20,\n",
    "#             num_workers=4,\n",
    "#             allowed_entity_types=None,\n",
    "#             allowed_relation_types=None,\n",
    "#             allowed_relation_props=[\"relationship_description\"],\n",
    "#             allowed_entity_props=[],\n",
    "#             parse_fn=parse_fn,\n",
    "#             extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Setup And Neo4J setup\n",
    "\n",
    "To launch Neo4j locally, first ensure you have docker installed. Then, you can launch the database with the following docker command.\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```\n",
    "From here, you can open the db at http://localhost:7474/. On this page, you will be asked to sign in. Use the default username/password of neo4j and neo4j.\n",
    "\n",
    "Once you login for the first time, you will be asked to change the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = GraphRAGStore(\n",
    "    username=\"neo4j\", password=\"password\", url=\"bolt://localhost:7687\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_response: ```plaintext\n",
      "(\"entity\"$$$$Grammar-Based Random Walker$$$$Entity$$$$A modified version of the random walker model used to calculate semantically meaningful primary eigenvector-based metrics in semantic networks, constrained by a user-defined grammar.)\n",
      "(\"entity\"$$$$Semantic Network$$$$Entity$$$$A network that qualifies the meaning of an edge relating any two vertices and is used for calculating semantic associations between vertices.)\n",
      "(\"entity\"$$$$Eigenvector Centrality$$$$Entity$$$$A metric derived from the random walker model to rank vertices in a semantic network based on their importance, influenced by a user-defined grammar.)\n",
      "(\"entity\"$$$$PageRank$$$$Entity$$$$A metric similar to eigenvector centrality used for ranking vertices in a semantic network based on their importance, influenced by a user-defined grammar.)\n",
      "(\"entity\"$$$$Resource Description Framework (RDF)$$$$Entity$$$$The data structure of the Semantic Web initiative that defines how information is represented and accessed, providing the context for understanding the final vertex ranking in random walkers.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$Semantic Network$$$$relates_to$$$$The model uses a user-defined grammar to rank vertices based on semantic associations within the network.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$Eigenvector Centrality$$$$calculates$$$$The modified random walker model calculates eigenvector centrality as one of the metrics for ranking vertices in a semantic network.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$PageRank$$$$related_to$$$$Both eigenvector centrality and PageRank are metrics used to rank vertices in a semantic network, influenced by the user-defined grammar in the random walker model.)\n",
      "(\"relationship\"$$$$Semantic Network$$$$Eigenvector Centrality$$$$contains$$$$The semantic network is the context within which eigenvector centrality is calculated to rank its vertices based on their importance.)\n",
      "(\"relationship\"$$$$Eigenvector Centrality$$$$PageRank$$$$similar_to$$$$Both metrics are used in the random walker model to rank vertices, with PageRank being a similar metric to eigenvector centrality.)\n",
      "(\"relationship\"$$$$Resource Description Framework (RDF)$$$$Semantic Network$$$$defines_context_for$$$$The RDF framework provides the context for understanding and interpreting the final vertex ranking in semantic networks.)\n",
      "```\n",
      "\n",
      "This output identifies key entities from the given text and their relationships, formatted according to the provided instructions.\n",
      "response_str: ```plaintext\n",
      "(\"entity\"$$$$Grammar-Based Random Walker$$$$Entity$$$$A modified version of the random walker model used to calculate semantically meaningful primary eigenvector-based metrics in semantic networks, constrained by a user-defined grammar.)\n",
      "(\"entity\"$$$$Semantic Network$$$$Entity$$$$A network that qualifies the meaning of an edge relating any two vertices and is used for calculating semantic associations between vertices.)\n",
      "(\"entity\"$$$$Eigenvector Centrality$$$$Entity$$$$A metric derived from the random walker model to rank vertices in a semantic network based on their importance, influenced by a user-defined grammar.)\n",
      "(\"entity\"$$$$PageRank$$$$Entity$$$$A metric similar to eigenvector centrality used for ranking vertices in a semantic network based on their importance, influenced by a user-defined grammar.)\n",
      "(\"entity\"$$$$Resource Description Framework (RDF)$$$$Entity$$$$The data structure of the Semantic Web initiative that defines how information is represented and accessed, providing the context for understanding the final vertex ranking in random walkers.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$Semantic Network$$$$relates_to$$$$The model uses a user-defined grammar to rank vertices based on semantic associations within the network.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$Eigenvector Centrality$$$$calculates$$$$The modified random walker model calculates eigenvector centrality as one of the metrics for ranking vertices in a semantic network.)\n",
      "(\"relationship\"$$$$Grammar-Based Random Walker$$$$PageRank$$$$related_to$$$$Both eigenvector centrality and PageRank are metrics used to rank vertices in a semantic network, influenced by the user-defined grammar in the random walker model.)\n",
      "(\"relationship\"$$$$Semantic Network$$$$Eigenvector Centrality$$$$contains$$$$The semantic network is the context within which eigenvector centrality is calculated to rank its vertices based on their importance.)\n",
      "(\"relationship\"$$$$Eigenvector Centrality$$$$PageRank$$$$similar_to$$$$Both metrics are used in the random walker model to rank vertices, with PageRank being a similar metric to eigenvector centrality.)\n",
      "(\"relationship\"$$$$Resource Description Framework (RDF)$$$$Semantic Network$$$$defines_context_for$$$$The RDF framework provides the context for understanding and interpreting the final vertex ranking in semantic networks.)\n",
      "```\n",
      "\n",
      "This output identifies key entities from the given text and their relationships, formatted according to the provided instructions.\n",
      "entities: []\n",
      "relationships: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_response: Here's the output for the given text, following the specified format:\n",
      "\n",
      "### Entities:\n",
      "1. (\"entity\"$$$$Belief Propagation$$$$Algorithm$$$$An iterative algorithm used in statistical inference on tree graphs that converges to a unique minimum of the Bethe free energy functional.\")\n",
      "2. (\"entity\"$$$$Graphical Model$$$$Model$$$$A model defined on a graph for statistical inference, which may or may not have loops.\")\n",
      "3. (\"entity\"$$$$Loopy Graph$$$$Graph$$$$A graph containing cycles or loops.\")\n",
      "4. (\"entity\"$$$$Bethe Free Energy Functional$$$$Functional$$$$An energy functional used in the context of graphical models and Belief Propagation algorithms that has multiple minima for loopy graphs.\")\n",
      "5. (\"entity\"$$$$Maximum-Likelihood (ML) Solution$$$$Solution$$$$The optimal solution in terms of maximizing the likelihood function, especially relevant in zero-temperature limit discussions.\")\n",
      "6. (\"entity\"$$$$Linear Programming (LP) Algorithm$$$$Algorithm$$$$An optimization algorithm used to solve problems with linear constraints and an objective function that is also linear.\")\n",
      "7. (\"entity\"$$$$Totally-Uni-Modular (TUM) Matrix of Constraints$$$$Matrix$$$$A matrix associated with the LP algorithm that has specific properties ensuring efficient solvability through certain algorithms.\")\n",
      "8. (\"entity\"$$$$g-BP Algorithm$$$$Algorithm$$$$An imagined algorithm used to find the global minimum of the Bethe free energy in the zero-temperature limit.)\n",
      "\n",
      "### Relationships:\n",
      "1. (\"relationship\"$$$$Belief Propagation$$$$Graphical Model$$$$Applies To$$$$Belief Propagation is a method applied to Graphical Models, especially those on tree structures.)\n",
      "2. (\"relationship\"$$$$Bethe Free Energy Functional$$$$Graphical Model$$$$Is Used In$$$$The Bethe free energy functional is used in the context of Graphical Models for optimization problems.)\n",
      "3. (\"relationship\"$$$$Maximum-Likelihood (ML) Solution$$$$Loopy Graph$$$$Found In$$$$In special cases, ML solutions can be found on Loopy Graphs through certain algorithms.)\n",
      "4. (\"relationship\"$$$$Linear Programming (LP) Algorithm$$$$Totally-Uni-Modular (TUM) Matrix of Constraints$$$$Relies On$$$$The LP algorithm's efficiency is guaranteed by the TUM matrix of constraints.)\n",
      "5. (\"relationship\"$$$$g-BP Algorithm$$$$Bethe Free Energy Functional$$$$Aims To Find$$$$The g-BP algorithm aims to find the global minimum of the Bethe free energy functional in the zero-temperature limit.)\n",
      "\n",
      "This output identifies entities and their types, as well as relationships between them based on the provided text.\n",
      "response_str: Here's the output for the given text, following the specified format:\n",
      "\n",
      "### Entities:\n",
      "1. (\"entity\"$$$$Belief Propagation$$$$Algorithm$$$$An iterative algorithm used in statistical inference on tree graphs that converges to a unique minimum of the Bethe free energy functional.\")\n",
      "2. (\"entity\"$$$$Graphical Model$$$$Model$$$$A model defined on a graph for statistical inference, which may or may not have loops.\")\n",
      "3. (\"entity\"$$$$Loopy Graph$$$$Graph$$$$A graph containing cycles or loops.\")\n",
      "4. (\"entity\"$$$$Bethe Free Energy Functional$$$$Functional$$$$An energy functional used in the context of graphical models and Belief Propagation algorithms that has multiple minima for loopy graphs.\")\n",
      "5. (\"entity\"$$$$Maximum-Likelihood (ML) Solution$$$$Solution$$$$The optimal solution in terms of maximizing the likelihood function, especially relevant in zero-temperature limit discussions.\")\n",
      "6. (\"entity\"$$$$Linear Programming (LP) Algorithm$$$$Algorithm$$$$An optimization algorithm used to solve problems with linear constraints and an objective function that is also linear.\")\n",
      "7. (\"entity\"$$$$Totally-Uni-Modular (TUM) Matrix of Constraints$$$$Matrix$$$$A matrix associated with the LP algorithm that has specific properties ensuring efficient solvability through certain algorithms.\")\n",
      "8. (\"entity\"$$$$g-BP Algorithm$$$$Algorithm$$$$An imagined algorithm used to find the global minimum of the Bethe free energy in the zero-temperature limit.)\n",
      "\n",
      "### Relationships:\n",
      "1. (\"relationship\"$$$$Belief Propagation$$$$Graphical Model$$$$Applies To$$$$Belief Propagation is a method applied to Graphical Models, especially those on tree structures.)\n",
      "2. (\"relationship\"$$$$Bethe Free Energy Functional$$$$Graphical Model$$$$Is Used In$$$$The Bethe free energy functional is used in the context of Graphical Models for optimization problems.)\n",
      "3. (\"relationship\"$$$$Maximum-Likelihood (ML) Solution$$$$Loopy Graph$$$$Found In$$$$In special cases, ML solutions can be found on Loopy Graphs through certain algorithms.)\n",
      "4. (\"relationship\"$$$$Linear Programming (LP) Algorithm$$$$Totally-Uni-Modular (TUM) Matrix of Constraints$$$$Relies On$$$$The LP algorithm's efficiency is guaranteed by the TUM matrix of constraints.)\n",
      "5. (\"relationship\"$$$$g-BP Algorithm$$$$Bethe Free Energy Functional$$$$Aims To Find$$$$The g-BP algorithm aims to find the global minimum of the Bethe free energy functional in the zero-temperature limit.)\n",
      "\n",
      "This output identifies entities and their types, as well as relationships between them based on the provided text.\n",
      "entities: []\n",
      "relationships: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_response: ### Step 1: Identify all entities\n",
      "\n",
      "1. (\"entity\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$An AI engine designed to map analogical relations between lists of words using a large corpus, introduced as an improvement over the Structure Mapping Engine.\")\n",
      "2. (\"entity\"$$$$Structure Mapping Theory (SMT)$$$$Theory$$$$A theory on computational modeling of analogy-making that emphasizes structure mapping for identifying similarities between two domains.)\n",
      "3. (\"entity\"$$$$Structure Mapping Engine (SME)$$$$Engine$$$$The implementation of SMT, which requires complex hand-coded representations to build analogical mappings between domain descriptions.)\n",
      "4. (\"entity\"$$$$Latent Relational Analysis (LRA)$$$$Analysis Technique$$$$A method for discovering semantic relations among words in a large corpus without requiring hand-coded representations.)\n",
      "5. (\"entity\"$$$$Algorithm and Experiments$$$$Documentation$$$$A document describing the Latent Relation Mapping Engine, its theoretical background, implementation details, and experimental evaluations.)\n",
      "\n",
      "### Step 2: Identify all pairs of (source_entity, target_entity) that are *clearly related* to each other\n",
      "\n",
      "1. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Theory (SMT)$$$$Inspired By$$$$LRME builds on the ideas from SMT but aims to eliminate hand-coded representations needed in SME.)\n",
      "2. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Engine (SME)$$$$Improves Upon$$$$LRME addresses a limitation of SME by using LRA to automatically discover semantic relations, thus reducing dependency on hand-coded representations.)\n",
      "3. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Latent Relational Analysis (LRA)$$$$Utilizes$$$$LRME uses the methods from LRA to discover semantic relations in raw text corpora without manual coding.)\n",
      "4. (\"relationship\"$$$$Structure Mapping Theory (SMT)$$$$Structure Mapping Engine (SME)$$$$Implementation Of$$$$SME is an implementation of SMT, designed to build analogical mappings between domain descriptions using complex hand-coded representations.)\n",
      "5. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$Describes$$$$The text document provides documentation about LRME's design, theory, implementation, and experimental results.)\n",
      "\n",
      "### Output:\n",
      "```\n",
      "(\"entity\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$An AI engine designed to map analogical relations between lists of words using a large corpus, introduced as an improvement over the Structure Mapping Engine.)\n",
      "(\"entity\"$$$$Structure Mapping Theory (SMT)$$$$Theory$$$$A theory on computational modeling of analogy-making that emphasizes structure mapping for identifying similarities between two domains.)\n",
      "(\"entity\"$$$$Structure Mapping Engine (SME)$$$$Engine$$$$The implementation of SMT, which requires complex hand-coded representations to build analogical mappings between domain descriptions.)\n",
      "(\"entity\"$$$$Latent Relational Analysis (LRA)$$$$Analysis Technique$$$$A method for discovering semantic relations among words in a large corpus without requiring hand-coded representations.)\n",
      "(\"entity\"$$$$Algorithm and Experiments$$$$Documentation$$$$A document describing the Latent Relation Mapping Engine, its theoretical background, implementation details, and experimental evaluations.)\n",
      "\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Theory (SMT)$$$$Inspired By$$$$LRME builds on the ideas from SMT but aims to eliminate hand-coded representations needed in SME.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Engine (SME)$$$$Improves Upon$$$$LRME addresses a limitation of SME by using LRA to automatically discover semantic relations, thus reducing dependency on hand-coded representations.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Latent Relational Analysis (LRA)$$$$Utilizes$$$$LRME uses the methods from LRA to discover semantic relations in raw text corpora without manual coding.)\n",
      "(\"relationship\"$$$$Structure Mapping Theory (SMT)$$$$Structure Mapping Engine (SME)$$$$Implementation Of$$$$SME is an implementation of SMT, designed to build analogical mappings between domain descriptions using complex hand-coded representations.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$Describes$$$$The text document provides documentation about LRME's design, theory, implementation, and experimental results.)\n",
      "```\n",
      "response_str: ### Step 1: Identify all entities\n",
      "\n",
      "1. (\"entity\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$An AI engine designed to map analogical relations between lists of words using a large corpus, introduced as an improvement over the Structure Mapping Engine.\")\n",
      "2. (\"entity\"$$$$Structure Mapping Theory (SMT)$$$$Theory$$$$A theory on computational modeling of analogy-making that emphasizes structure mapping for identifying similarities between two domains.)\n",
      "3. (\"entity\"$$$$Structure Mapping Engine (SME)$$$$Engine$$$$The implementation of SMT, which requires complex hand-coded representations to build analogical mappings between domain descriptions.)\n",
      "4. (\"entity\"$$$$Latent Relational Analysis (LRA)$$$$Analysis Technique$$$$A method for discovering semantic relations among words in a large corpus without requiring hand-coded representations.)\n",
      "5. (\"entity\"$$$$Algorithm and Experiments$$$$Documentation$$$$A document describing the Latent Relation Mapping Engine, its theoretical background, implementation details, and experimental evaluations.)\n",
      "\n",
      "### Step 2: Identify all pairs of (source_entity, target_entity) that are *clearly related* to each other\n",
      "\n",
      "1. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Theory (SMT)$$$$Inspired By$$$$LRME builds on the ideas from SMT but aims to eliminate hand-coded representations needed in SME.)\n",
      "2. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Engine (SME)$$$$Improves Upon$$$$LRME addresses a limitation of SME by using LRA to automatically discover semantic relations, thus reducing dependency on hand-coded representations.)\n",
      "3. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Latent Relational Analysis (LRA)$$$$Utilizes$$$$LRME uses the methods from LRA to discover semantic relations in raw text corpora without manual coding.)\n",
      "4. (\"relationship\"$$$$Structure Mapping Theory (SMT)$$$$Structure Mapping Engine (SME)$$$$Implementation Of$$$$SME is an implementation of SMT, designed to build analogical mappings between domain descriptions using complex hand-coded representations.)\n",
      "5. (\"relationship\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$Describes$$$$The text document provides documentation about LRME's design, theory, implementation, and experimental results.)\n",
      "\n",
      "### Output:\n",
      "```\n",
      "(\"entity\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$An AI engine designed to map analogical relations between lists of words using a large corpus, introduced as an improvement over the Structure Mapping Engine.)\n",
      "(\"entity\"$$$$Structure Mapping Theory (SMT)$$$$Theory$$$$A theory on computational modeling of analogy-making that emphasizes structure mapping for identifying similarities between two domains.)\n",
      "(\"entity\"$$$$Structure Mapping Engine (SME)$$$$Engine$$$$The implementation of SMT, which requires complex hand-coded representations to build analogical mappings between domain descriptions.)\n",
      "(\"entity\"$$$$Latent Relational Analysis (LRA)$$$$Analysis Technique$$$$A method for discovering semantic relations among words in a large corpus without requiring hand-coded representations.)\n",
      "(\"entity\"$$$$Algorithm and Experiments$$$$Documentation$$$$A document describing the Latent Relation Mapping Engine, its theoretical background, implementation details, and experimental evaluations.)\n",
      "\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Theory (SMT)$$$$Inspired By$$$$LRME builds on the ideas from SMT but aims to eliminate hand-coded representations needed in SME.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Structure Mapping Engine (SME)$$$$Improves Upon$$$$LRME addresses a limitation of SME by using LRA to automatically discover semantic relations, thus reducing dependency on hand-coded representations.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Latent Relational Analysis (LRA)$$$$Utilizes$$$$LRME uses the methods from LRA to discover semantic relations in raw text corpora without manual coding.)\n",
      "(\"relationship\"$$$$Structure Mapping Theory (SMT)$$$$Structure Mapping Engine (SME)$$$$Implementation Of$$$$SME is an implementation of SMT, designed to build analogical mappings between domain descriptions using complex hand-coded representations.)\n",
      "(\"relationship\"$$$$Latent Relation Mapping Engine$$$$Algorithm and Experiments$$$$Describes$$$$The text document provides documentation about LRME's design, theory, implementation, and experimental results.)\n",
      "```\n",
      "entities: []\n",
      "relationships: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_response: ### Step 1: Identify All Entities\n",
      "\n",
      "1. (\"entity\"$$$$Garg$$$$Person$$$$Garg is a person who recently proved something about access control logics.\")\n",
      "2. (\"entity\"$$$$Abadi$$$$Person$$$$Abadi is a person who, along with Garg, recently proved something about access control logics.\")\n",
      "3. (\"entity\"$$$$AccessControlLogics$$$$System$$$$A set of logical systems used for controlling access to resources in information security.\")\n",
      "4. (\"entity\"$$$$ModalLogicS4$$$$System$$$$A modal logic system that is part of the AccessControlLogics framework and was involved in the proof with Garg and Abadi.\")\n",
      "5. (\"entity\"$$$$NormalMultimodalLogics$$$$System$$$$A family of logics, including monomodal logics K and S4, which can be embedded in simple type theory according to previous work.\")\n",
      "6. (\"entity\"$$$$SimpleTypeTheory$$$$System$$$$A logical framework where normal multimodal logics, including S4, can be embedded as demonstrated by earlier work.\")\n",
      "7. (\"entity\"$$$$HigherOrderLogic$$$$System$$$$Synonymous with SimpleTypeTheory and is the system in which normal multimodal logics are embedded according to previous research.\")\n",
      "8. (\"entity\"$$$$LEO-II$$$$Tool$$$$A higher-order theorem prover that has been used to automate reasoning about simple type theory and normal multimodal logics, including S4.\")\n",
      "\n",
      "### Step 2: Identify Relationships\n",
      "\n",
      "1. (\"relationship\"$$$$GargAbadi$$Garg$$$$Abadi$$$$Collaboration$$$$Garg and Abadi have collaborated on proving something related to access control logics.\")\n",
      "2. (\"relationship\"$$$$ProvedAccessControlLogics$$Garg$$$$AccessControlLogics$$$$Proof$$$Garg proved that prominent access control logics can be translated into S4 in a sound and complete way.\")\n",
      "3. (\"relationship\"$$$$EmbeddedNormalMultimodalLogics$$NormalMultimodalLogics$$$$SimpleTypeTheory$$$$Embedding$$$The normal multimodal logics, including K and S4, can be embedded in simple type theory as previously outlined.\")\n",
      "4. (\"relationship\"$$$$LEO-IIAutomatesReasoning$$LEO-II$$$$SimpleTypeTheory$$$$Automation$$$LEO-II is used to automate reasoning about the embeddings of normal multimodal logics in simple type theory.\")\n",
      "5. (\"relationship\"$$$$LEO-IIAutomatesAccessControlLogics$$LEO-II$$$$AccessControlLogics$$$$Application$$$LEO-II can be applied to automate reasoning in prominent access control logics using the framework described.\")\n",
      "\n",
      "### Final Output\n",
      "\n",
      "(\"entity\"$$$$Garg$$$$Person$$$$Garg is a person who recently proved something about access control logics.\")\n",
      "(\"entity\"$$$$Abadi$$$$Person$$$$Abadi is a person who, along with Garg, recently proved something about access control logics.\")\n",
      "(\"entity\"$$$$AccessControlLogics$$$$System$$$$A set of logical systems used for controlling access to resources in information security.\")\n",
      "(\"entity\"$$$$ModalLogicS4$$$$System$$$$A modal logic system that is part of the AccessControlLogics framework and was involved in the proof with Garg and Abadi.)\n",
      "(\"entity\"$$$$NormalMultimodalLogics$$$$System$$$$A family of logics, including monomodal logics K and S4, which can be embedded in simple type theory according to previous work.\")\n",
      "(\"entity\"$$$$SimpleTypeTheory$$$$System$$$$A logical framework where normal multimodal logics, including S4, can be embedded as demonstrated by earlier research.)\n",
      "(\"entity\"$$$$HigherOrderLogic$$$$System$$$$Synonymous with SimpleTypeTheory and is the system in which normal multimodal logics are embedded according to previous research.)\n",
      "(\"entity\"$$$$LEO-II$$$$Tool$$$$A higher-order theorem prover that has been used to automate reasoning about simple type theory and normal multimodal logics, including S4.)\n",
      "(\"relationship\"$$$$GargAbadi$$Garg$$$$Abadi$$$$Collaboration$$$Garg and Abadi have collaborated on proving something related to access control logics.)\n",
      "(\"relationship\"$$$$ProvedAccessControlLogics$$Garg$$$$AccessControlLogics$$$Garg proved that prominent access control logics can be translated into S4 in a sound and complete way.)\n",
      "(\"relationship\"$$$$EmbeddedNormalMultimodalLogics$$NormalMultimodalLogics$$$$SimpleTypeTheory$$$$Embedding$$$The normal multimodal logics, including K and S4, can be embedded in simple type theory as previously outlined.)\n",
      "(\"relationship\"$$$$LEO-IIAutomatesReasoning$$LEO-II$$$$SimpleTypeTheory$$$$Automation$$$LEO-II is used to automate reasoning about the embeddings of normal multimodal logics in simple type theory.)\n",
      "(\"relationship\"$$$$LEO-IIAutomatesAccessControlLogics$$LEO-II$$$$AccessControlLogics$$$$Application$$$LEO-II can be applied to automate reasoning in prominent access control logics using the framework described.)\n",
      "response_str: ### Step 1: Identify All Entities\n",
      "\n",
      "1. (\"entity\"$$$$Garg$$$$Person$$$$Garg is a person who recently proved something about access control logics.\")\n",
      "2. (\"entity\"$$$$Abadi$$$$Person$$$$Abadi is a person who, along with Garg, recently proved something about access control logics.\")\n",
      "3. (\"entity\"$$$$AccessControlLogics$$$$System$$$$A set of logical systems used for controlling access to resources in information security.\")\n",
      "4. (\"entity\"$$$$ModalLogicS4$$$$System$$$$A modal logic system that is part of the AccessControlLogics framework and was involved in the proof with Garg and Abadi.\")\n",
      "5. (\"entity\"$$$$NormalMultimodalLogics$$$$System$$$$A family of logics, including monomodal logics K and S4, which can be embedded in simple type theory according to previous work.\")\n",
      "6. (\"entity\"$$$$SimpleTypeTheory$$$$System$$$$A logical framework where normal multimodal logics, including S4, can be embedded as demonstrated by earlier work.\")\n",
      "7. (\"entity\"$$$$HigherOrderLogic$$$$System$$$$Synonymous with SimpleTypeTheory and is the system in which normal multimodal logics are embedded according to previous research.\")\n",
      "8. (\"entity\"$$$$LEO-II$$$$Tool$$$$A higher-order theorem prover that has been used to automate reasoning about simple type theory and normal multimodal logics, including S4.\")\n",
      "\n",
      "### Step 2: Identify Relationships\n",
      "\n",
      "1. (\"relationship\"$$$$GargAbadi$$Garg$$$$Abadi$$$$Collaboration$$$$Garg and Abadi have collaborated on proving something related to access control logics.\")\n",
      "2. (\"relationship\"$$$$ProvedAccessControlLogics$$Garg$$$$AccessControlLogics$$$$Proof$$$Garg proved that prominent access control logics can be translated into S4 in a sound and complete way.\")\n",
      "3. (\"relationship\"$$$$EmbeddedNormalMultimodalLogics$$NormalMultimodalLogics$$$$SimpleTypeTheory$$$$Embedding$$$The normal multimodal logics, including K and S4, can be embedded in simple type theory as previously outlined.\")\n",
      "4. (\"relationship\"$$$$LEO-IIAutomatesReasoning$$LEO-II$$$$SimpleTypeTheory$$$$Automation$$$LEO-II is used to automate reasoning about the embeddings of normal multimodal logics in simple type theory.\")\n",
      "5. (\"relationship\"$$$$LEO-IIAutomatesAccessControlLogics$$LEO-II$$$$AccessControlLogics$$$$Application$$$LEO-II can be applied to automate reasoning in prominent access control logics using the framework described.\")\n",
      "\n",
      "### Final Output\n",
      "\n",
      "(\"entity\"$$$$Garg$$$$Person$$$$Garg is a person who recently proved something about access control logics.\")\n",
      "(\"entity\"$$$$Abadi$$$$Person$$$$Abadi is a person who, along with Garg, recently proved something about access control logics.\")\n",
      "(\"entity\"$$$$AccessControlLogics$$$$System$$$$A set of logical systems used for controlling access to resources in information security.\")\n",
      "(\"entity\"$$$$ModalLogicS4$$$$System$$$$A modal logic system that is part of the AccessControlLogics framework and was involved in the proof with Garg and Abadi.)\n",
      "(\"entity\"$$$$NormalMultimodalLogics$$$$System$$$$A family of logics, including monomodal logics K and S4, which can be embedded in simple type theory according to previous work.\")\n",
      "(\"entity\"$$$$SimpleTypeTheory$$$$System$$$$A logical framework where normal multimodal logics, including S4, can be embedded as demonstrated by earlier research.)\n",
      "(\"entity\"$$$$HigherOrderLogic$$$$System$$$$Synonymous with SimpleTypeTheory and is the system in which normal multimodal logics are embedded according to previous research.)\n",
      "(\"entity\"$$$$LEO-II$$$$Tool$$$$A higher-order theorem prover that has been used to automate reasoning about simple type theory and normal multimodal logics, including S4.)\n",
      "(\"relationship\"$$$$GargAbadi$$Garg$$$$Abadi$$$$Collaboration$$$Garg and Abadi have collaborated on proving something related to access control logics.)\n",
      "(\"relationship\"$$$$ProvedAccessControlLogics$$Garg$$$$AccessControlLogics$$$Garg proved that prominent access control logics can be translated into S4 in a sound and complete way.)\n",
      "(\"relationship\"$$$$EmbeddedNormalMultimodalLogics$$NormalMultimodalLogics$$$$SimpleTypeTheory$$$$Embedding$$$The normal multimodal logics, including K and S4, can be embedded in simple type theory as previously outlined.)\n",
      "(\"relationship\"$$$$LEO-IIAutomatesReasoning$$LEO-II$$$$SimpleTypeTheory$$$$Automation$$$LEO-II is used to automate reasoning about the embeddings of normal multimodal logics in simple type theory.)\n",
      "(\"relationship\"$$$$LEO-IIAutomatesAccessControlLogics$$LEO-II$$$$AccessControlLogics$$$$Application$$$LEO-II can be applied to automate reasoning in prominent access control logics using the framework described.)\n",
      "entities: []\n",
      "relationships: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Extracting paths from text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:35<00:00, 19.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_response: Let's go through each step for the provided text.\n",
      "\n",
      "### Step 1: Identify All Entities\n",
      "\n",
      "**Entities:**\n",
      "\n",
      "1. (\"entity\"$$$$Faster and better: a machine learning approach to corner detection$$$$Text$$$\n",
      "The paper about using machine learning for improving corner detection in image processing.)\n",
      "\n",
      "2. (\"entity\"$$$$repeatability$$$$Concept$$$\n",
      "A property of a detector that ensures the same feature is detected regardless of viewpoint changes [Schmid et al 2000].)\n",
      "\n",
      "3. (\"entity\"$$$$efficiency$$$$Concept$$$\n",
      "Determines whether the detector can process at frame rate.)\n",
      "\n",
      "4. (\"entity\"$$$$corner detection$$$$Technique$$$\n",
      "The method used for identifying corners in images or scenes.)\n",
      "\n",
      "5. (\"entity\"$$$$feature detection$$$$Technique$$$\n",
      "The broader category of detecting features such as corners, edges, etc., within an image.)\n",
      "\n",
      "6. (\"entity\"$$$$machine learning approach$$$$Method$$$\n",
      "Using machine learning to derive a feature detector from a heuristic method.)\n",
      "\n",
      "7. (\"entity\"$$$$Harris detector$$$$Tool$$$\n",
      "A traditional corner detection algorithm that operates at 115% of processing time compared to the new detector.)\n",
      "\n",
      "8. (\"entity\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$Tool$$$\n",
      "A state-of-the-art feature descriptor that takes 195% more processing time than the new detector.)\n",
      "\n",
      "9. (\"entity\"$$$$PAL video$$$$Input$$$\n",
      "A specific type of video format used as input for testing the detector.)\n",
      "\n",
      "### Step 2: Identify Relationships\n",
      "\n",
      "**Relationships:**\n",
      "\n",
      "1. (\"relationship\"$$$$repeatability$$$$corner detection$$$$Requirement$$$\n",
      "Corner detection must be repeatable to ensure consistent feature identification in different viewpoints.)\n",
      "\n",
      "2. (\"relationship\"$$$$efficiency$$$$corner detection$$$$Performance$$$\n",
      "Efficient corner detection is necessary for real-time processing and frame rate operation.)\n",
      "\n",
      "3. (\"relationship\"$$$$machine learning approach$$$$feature detection$$$$Derivation$$$\n",
      "A new machine learning-based method derived from a heuristic to detect features such as corners.)\n",
      "\n",
      "4. (\"relationship\"$$$$Harris detector$$$$corner detection$$$$Comparison$$$\n",
      "Used as a benchmark for comparison with the new machine learning approach, showing it is less efficient.)\n",
      "\n",
      "5. (\"relationship\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$corner detection$$$$Comparison$$$\n",
      "Another state-of-the-art tool compared against the new method, which outperforms it in terms of both speed and quality.)\n",
      "\n",
      "6. (\"relationship\"$$$$PAL video$$$$input for testing$$$$Type of Input$$$\n",
      "Specific type of input used to test the robustness and efficiency of the corner detector under real-world conditions.)\n",
      "\n",
      "### Final Output\n",
      "\n",
      "```plaintext\n",
      "(\"entity\"$$$$Faster and better: a machine learning approach to corner detection$$$$Text$$$\n",
      "The paper about using machine learning for improving corner detection in image processing.)\n",
      "\n",
      "(\"entity\"$$$$repeatability$$$$Concept$$$\n",
      "A property of a detector that ensures the same feature is detected regardless of viewpoint changes [Schmid et al 2000].)\n",
      "\n",
      "(\"entity\"$$$$efficiency$$$$Concept$$$\n",
      "Determines whether the detector can process at frame rate.)\n",
      "\n",
      "(\"entity\"$$$$corner detection$$$$Technique$$$\n",
      "The method used for identifying corners in images or scenes.)\n",
      "\n",
      "(\"entity\"$$$$feature detection$$$$Technique$$$\n",
      "The broader category of detecting features such as corners, edges, etc., within an image.)\n",
      "\n",
      "(\"entity\"$$$$machine learning approach$$$$Method$$$\n",
      "Using machine learning to derive a feature detector from a heuristic method.)\n",
      "\n",
      "(\"entity\"$$$$Harris detector$$$$Tool$$$\n",
      "A traditional corner detection algorithm that operates at 115% of processing time compared to the new detector.)\n",
      "\n",
      "(\"entity\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$Tool$$$\n",
      "A state-of-the-art feature descriptor that takes 195% more processing time than the new detector.)\n",
      "\n",
      "(\"entity\"$$$$PAL video$$$$Input$$$\n",
      "A specific type of video format used as input for testing the detector.)\n",
      "\n",
      "(\"relationship\"$$$$repeatability$$$$corner detection$$$$Requirement$$$\n",
      "Corner detection must be repeatable to ensure consistent feature identification in different viewpoints.)\n",
      "\n",
      "(\"relationship\"$$$$efficiency$$$$corner detection$$$$Performance$$$\n",
      "Efficient corner detection is necessary for real-time processing and frame rate operation.)\n",
      "\n",
      "(\"relationship\"$$$$machine learning approach$$$$feature detection$$$$Derivation$$$\n",
      "A new machine learning-based method derived from a heuristic to detect features such as corners.)\n",
      "\n",
      "(\"relationship\"$$$$Harris detector$$$$corner detection$$$$Comparison$$$\n",
      "Used as a benchmark for comparison with the new machine learning approach, showing it is less efficient.)\n",
      "\n",
      "(\"relationship\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$corner detection$$$$Comparison$$$\n",
      "Another state-of-the-art tool compared against the new method, which outperforms it in terms of both speed and quality.)\n",
      "\n",
      "(\"relationship\"$$$$PAL video$$$$input for testing$$$$Type of Input$$$\n",
      "Specific type of input used to test the robustness and efficiency of the corner detector under real-world conditions.)\n",
      "```\n",
      "\n",
      "This output provides a comprehensive breakdown of entities and their relationships as identified from the text.\n",
      "response_str: Let's go through each step for the provided text.\n",
      "\n",
      "### Step 1: Identify All Entities\n",
      "\n",
      "**Entities:**\n",
      "\n",
      "1. (\"entity\"$$$$Faster and better: a machine learning approach to corner detection$$$$Text$$$\n",
      "The paper about using machine learning for improving corner detection in image processing.)\n",
      "\n",
      "2. (\"entity\"$$$$repeatability$$$$Concept$$$\n",
      "A property of a detector that ensures the same feature is detected regardless of viewpoint changes [Schmid et al 2000].)\n",
      "\n",
      "3. (\"entity\"$$$$efficiency$$$$Concept$$$\n",
      "Determines whether the detector can process at frame rate.)\n",
      "\n",
      "4. (\"entity\"$$$$corner detection$$$$Technique$$$\n",
      "The method used for identifying corners in images or scenes.)\n",
      "\n",
      "5. (\"entity\"$$$$feature detection$$$$Technique$$$\n",
      "The broader category of detecting features such as corners, edges, etc., within an image.)\n",
      "\n",
      "6. (\"entity\"$$$$machine learning approach$$$$Method$$$\n",
      "Using machine learning to derive a feature detector from a heuristic method.)\n",
      "\n",
      "7. (\"entity\"$$$$Harris detector$$$$Tool$$$\n",
      "A traditional corner detection algorithm that operates at 115% of processing time compared to the new detector.)\n",
      "\n",
      "8. (\"entity\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$Tool$$$\n",
      "A state-of-the-art feature descriptor that takes 195% more processing time than the new detector.)\n",
      "\n",
      "9. (\"entity\"$$$$PAL video$$$$Input$$$\n",
      "A specific type of video format used as input for testing the detector.)\n",
      "\n",
      "### Step 2: Identify Relationships\n",
      "\n",
      "**Relationships:**\n",
      "\n",
      "1. (\"relationship\"$$$$repeatability$$$$corner detection$$$$Requirement$$$\n",
      "Corner detection must be repeatable to ensure consistent feature identification in different viewpoints.)\n",
      "\n",
      "2. (\"relationship\"$$$$efficiency$$$$corner detection$$$$Performance$$$\n",
      "Efficient corner detection is necessary for real-time processing and frame rate operation.)\n",
      "\n",
      "3. (\"relationship\"$$$$machine learning approach$$$$feature detection$$$$Derivation$$$\n",
      "A new machine learning-based method derived from a heuristic to detect features such as corners.)\n",
      "\n",
      "4. (\"relationship\"$$$$Harris detector$$$$corner detection$$$$Comparison$$$\n",
      "Used as a benchmark for comparison with the new machine learning approach, showing it is less efficient.)\n",
      "\n",
      "5. (\"relationship\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$corner detection$$$$Comparison$$$\n",
      "Another state-of-the-art tool compared against the new method, which outperforms it in terms of both speed and quality.)\n",
      "\n",
      "6. (\"relationship\"$$$$PAL video$$$$input for testing$$$$Type of Input$$$\n",
      "Specific type of input used to test the robustness and efficiency of the corner detector under real-world conditions.)\n",
      "\n",
      "### Final Output\n",
      "\n",
      "```plaintext\n",
      "(\"entity\"$$$$Faster and better: a machine learning approach to corner detection$$$$Text$$$\n",
      "The paper about using machine learning for improving corner detection in image processing.)\n",
      "\n",
      "(\"entity\"$$$$repeatability$$$$Concept$$$\n",
      "A property of a detector that ensures the same feature is detected regardless of viewpoint changes [Schmid et al 2000].)\n",
      "\n",
      "(\"entity\"$$$$efficiency$$$$Concept$$$\n",
      "Determines whether the detector can process at frame rate.)\n",
      "\n",
      "(\"entity\"$$$$corner detection$$$$Technique$$$\n",
      "The method used for identifying corners in images or scenes.)\n",
      "\n",
      "(\"entity\"$$$$feature detection$$$$Technique$$$\n",
      "The broader category of detecting features such as corners, edges, etc., within an image.)\n",
      "\n",
      "(\"entity\"$$$$machine learning approach$$$$Method$$$\n",
      "Using machine learning to derive a feature detector from a heuristic method.)\n",
      "\n",
      "(\"entity\"$$$$Harris detector$$$$Tool$$$\n",
      "A traditional corner detection algorithm that operates at 115% of processing time compared to the new detector.)\n",
      "\n",
      "(\"entity\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$Tool$$$\n",
      "A state-of-the-art feature descriptor that takes 195% more processing time than the new detector.)\n",
      "\n",
      "(\"entity\"$$$$PAL video$$$$Input$$$\n",
      "A specific type of video format used as input for testing the detector.)\n",
      "\n",
      "(\"relationship\"$$$$repeatability$$$$corner detection$$$$Requirement$$$\n",
      "Corner detection must be repeatable to ensure consistent feature identification in different viewpoints.)\n",
      "\n",
      "(\"relationship\"$$$$efficiency$$$$corner detection$$$$Performance$$$\n",
      "Efficient corner detection is necessary for real-time processing and frame rate operation.)\n",
      "\n",
      "(\"relationship\"$$$$machine learning approach$$$$feature detection$$$$Derivation$$$\n",
      "A new machine learning-based method derived from a heuristic to detect features such as corners.)\n",
      "\n",
      "(\"relationship\"$$$$Harris detector$$$$corner detection$$$$Comparison$$$\n",
      "Used as a benchmark for comparison with the new machine learning approach, showing it is less efficient.)\n",
      "\n",
      "(\"relationship\"$$$$SIFT (Scale-Invariant Feature Transform)$$$$corner detection$$$$Comparison$$$\n",
      "Another state-of-the-art tool compared against the new method, which outperforms it in terms of both speed and quality.)\n",
      "\n",
      "(\"relationship\"$$$$PAL video$$$$input for testing$$$$Type of Input$$$\n",
      "Specific type of input used to test the robustness and efficiency of the corner detector under real-world conditions.)\n",
      "```\n",
      "\n",
      "This output provides a comprehensive breakdown of entities and their relationships as identified from the text.\n",
      "entities: []\n",
      "relationships: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# PropertyGraphIndex.from_documents(\n",
    "#             documents,\n",
    "#             property_graph_store=graph_store,\n",
    "#             llm=self.llm,\n",
    "#             embed_model=self.embed_model,\n",
    "#             embed_kg_nodes=True,\n",
    "#             kg_extractors=[self.kg_extractor],\n",
    "#             show_progress=True\n",
    "# )\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    llm=llm,\n",
    "    show_progress=True,\n",
    "    embed_model=HuggingFaceEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='DEFINED_ON', source_id='Graphical Model', target_id='arbitrary graphical model', properties={'type': 'graph', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'arbitrary graphical model', 'type': 'arbitrary', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='arbitrary graphical model')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='SOLVED_EXACTLY_AND_EFFICIENTLY', source_id='Graphical Model', target_id='tree (graph without loops)', properties={'method': 'BP algorithm', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='GRAPHICAL_STRUCTURE', embedding=None, properties={'id': 'tree (graph without loops)', 'type': 'tree', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='tree (graph without loops)')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='MAY_SHOW_MULTIPLE_MINIMA', source_id='Graphical Model', target_id='Bethe free energy functional', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='FUNCTIONAL', embedding=None, properties={'id': 'Bethe free energy functional', 'type': 'Bethe', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Bethe free energy functional')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='MAY_CONVERGE_INCOMPLETELY', source_id='Graphical Model', target_id='zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='TEMPERATURE_STATE', embedding=None, properties={'id': 'zero-temperature limit', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature limit')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='DOES_NOT_GUARANTEE_GLOBAL_MINIMUM', source_id='Graphical Model', target_id='ML solution in the zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='SOLUTION', embedding=None, properties={'id': 'ML solution in the zero-temperature limit', 'type': 'Maximum-Likelihood', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='ML solution in the zero-temperature limit')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='HAS_EXCEPTIONS', source_id='Graphical Model', target_id='zero-temperature version of the BP algorithm finds ML solution', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='EXCEPTION', embedding=None, properties={'id': 'zero-temperature version of the BP algorithm finds ML solution', 'type': 'finds', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature version of the BP algorithm finds ML solution')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='SHARES_KEY_FEATURE', source_id='Graphical Model', target_id='two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='MODEL', embedding=None, properties={'id': 'two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E', 'reference': ['<cite>05KW</cite>', '<cite>08BSS</cite>'], 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='CONSIDERED', source_id='Graphical Model', target_id='g-BP algorithm', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='ALGORITHM', embedding=None, properties={'id': 'g-BP algorithm', 'type': 'gedanken', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP algorithm')],\n",
       " [EntityNode(label='ALGORITHM', embedding=None, properties={'id': 'g-BP Algorithm', 'type': 'gedanken', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP Algorithm'),\n",
       "  Relation(label='FUNDS', source_id='g-BP Algorithm', target_id='zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='TEMPERATURE_STATE', embedding=None, properties={'id': 'zero-temperature limit', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature limit')],\n",
       " [EntityNode(label='OUTPUT', embedding=None, properties={'id': 'g-BP Algorithm output', 'type': 'solution', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP Algorithm output'),\n",
       "  Relation(label='EQUALS', source_id='g-BP Algorithm output', target_id='limit of zero temperature', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='LIMIT', embedding=None, properties={'id': 'limit of zero temperature', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='limit of zero temperature')],\n",
       " [EntityNode(label='RESEARCH_TOPIC', embedding=None, properties={'id': 'Grammar-Based Random Walkers', 'prop1': 'area of study', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Grammar-Based Random Walkers'),\n",
       "  Relation(label='APPLIES_TO', source_id='Grammar-Based Random Walkers', target_id='Semantic Networks', properties={'prop1': 'context', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='NETWORK', embedding=None, properties={'id': 'Semantic Networks', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Semantic Networks')],\n",
       " [EntityNode(label='NETWORK', embedding=None, properties={'id': 'Semantic networks', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Semantic networks'),\n",
       "  Relation(label='QUALIFIES_MEANING_OF', source_id='Semantic networks', target_id='edge', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='EDGE', embedding=None, properties={'id': 'edge', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='edge')],\n",
       " [EntityNode(label='EDGE', embedding=None, properties={'id': 'edge', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='edge'),\n",
       "  Relation(label='RELATES', source_id='edge', target_id='two vertices', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='VERTEX', embedding=None, properties={'id': 'two vertices', 'prop1': 'number', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='two vertices')],\n",
       " [EntityNode(label='QUESTION', embedding=None, properties={'id': 'which vertices are most  central ', 'prop1': 'question', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='which vertices are most \"central\"'),\n",
       "  Relation(label='IS_DIFFICULT_TO_DETERMINE', source_id='which vertices are most \"central\"', target_id='in a semantic network', properties={'prop1': 'state', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='NETWORK', embedding=None, properties={'id': 'in a semantic network', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='in a semantic network')],\n",
       " [EntityNode(label='RELATIONSHIP', embedding=None, properties={'id': 'one relationship type', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='one relationship type'),\n",
       "  Relation(label='MAY_BE_DEEMED', source_id='one relationship type', target_id='subjectively more important', properties={'prop1': 'state', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='STATE', embedding=None, properties={'id': 'subjectively more important', 'prop1': 'description', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='subjectively more important')],\n",
       " [EntityNode(label='RESEARCH', embedding=None, properties={'id': 'research into semantic network metrics', 'prop1': 'focus', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='research into semantic network metrics'),\n",
       "  Relation(label='HAS_FOCUSED_PRIMARILY_ON', source_id='research into semantic network metrics', target_id='context-based rankings', properties={'prop1': 'area', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='RANKING', embedding=None, properties={'id': 'context-based rankings', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='context-based rankings')],\n",
       " [EntityNode(label='RANKING', embedding=None, properties={'id': 'context-based rankings', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='context-based rankings'),\n",
       "  Relation(label='I.E.', source_id='context-based rankings', target_id='user prescribed contexts', properties={'prop1': 'represents', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='CONTEXT', embedding=None, properties={'id': 'user prescribed contexts', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='user prescribed contexts')],\n",
       " [EntityNode(label='METRIC', embedding=None, properties={'id': 'many of the current semantic network metrics', 'prop1': 'category', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='many of the current semantic network metrics'),\n",
       "  Relation(label='RANK', source_id='many of the current semantic network metrics', target_id='semantic associations', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='ASSOCIATION', embedding=None, properties={'id': 'semantic associations', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='semantic associations')],\n",
       " [EntityNode(label='ASSOCIATION', embedding=None, properties={'id': 'semantic associations', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='semantic associations'),\n",
       "  Relation(label='REPRESENTED_BY', source_id='semantic associations', target_id='directed paths between two vertices', properties={'prop1': 'represents', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='PATH', embedding=None, properties={'id': 'directed paths between two vertices', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='directed paths between two vertices')],\n",
       " [EntityNode(label='CONCEPT', embedding=None, properties={'id': 'Random walkers, in the context of this article', 'prop1': 'context', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Random walkers, in the context of this article'),\n",
       "  Relation(label='ARE_CONSTRAINED_BY', source_id='Random walkers, in the context of this article', target_id='a grammar', properties={'prop1': 'condition', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='DATA_STRUCTURE', embedding=None, properties={'id': 'a grammar', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='a grammar')],\n",
       " [EntityNode(label='DATA_STRUCTURE', embedding=None, properties={'id': 'a grammar', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='a grammar'),\n",
       "  Relation(label='DETERMINES_THE', source_id='a grammar', target_id='meaning of the final vertex ranking', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='RANKING', embedding=None, properties={'id': 'meaning of the final vertex ranking', 'prop1': 'output', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='meaning of the final vertex ranking')],\n",
       " [EntityNode(label='STANDARD', embedding=None, properties={'id': 'Resource Description Framework (RDF)', 'prop1': 'name', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Resource Description Framework (RDF)'),\n",
       "  Relation(label='OF', source_id='Resource Description Framework (RDF)', target_id='the Semantic Web initiative', properties={'prop1': 'connection', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='INITIATIVE', embedding=None, properties={'id': 'the Semantic Web initiative', 'prop1': 'group', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='the Semantic Web initiative')],\n",
       " [EntityNode(label='ARTICLE_TITLE', embedding=None, properties={'id': 'Faster and better', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Faster and better'),\n",
       "  Relation(label='DISCUSSES', source_id='Faster and better', target_id='machine learning approach to corner detection', properties={'discussion_topic': ['machine learning approach to corner detection'], 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='RESEARCH_TOPIC', embedding=None, properties={'id': 'machine learning approach to corner detection', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='machine learning approach to corner detection')],\n",
       " [EntityNode(label='CORNER_DETECTOR_PROPERTIES', embedding=None, properties={'id': 'repeatability and efficiency', 'importance': 'real-world application', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='repeatability and efficiency'),\n",
       "  Relation(label='AFFECTS', source_id='repeatability and efficiency', target_id='usefulness of a corner detector', properties={'impact': 'usefulness', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='UTILITY', embedding=None, properties={'id': 'usefulness of a corner detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='usefulness of a corner detector')],\n",
       " [EntityNode(label='SCENE', embedding=None, properties={'id': 'same scene viewed from different positions', 'viewing_position': 'different', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='same scene viewed from different positions'),\n",
       "  Relation(label='SHOULD YIELD', source_id='same scene viewed from different positions', target_id='features which correspond to the same real-world 3D locations', properties={'correspondence': 'real-world 3D locations', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='FEATURES', embedding=None, properties={'id': 'features which correspond to the same real-world 3D locations', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='features which correspond to the same real-world 3D locations')],\n",
       " [EntityNode(label='REFERENCE', embedding=None, properties={'id': 'Schmid et al 2000', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Schmid et al 2000'),\n",
       "  Relation(label='CITES', source_id='Schmid et al 2000', target_id='repeatability criterion', properties={'work': 'repeatability criterion', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='CRITERION', embedding=None, properties={'id': 'repeatability criterion', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='repeatability criterion')],\n",
       " [EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'Harris detector', 'processing_time': '115%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Harris detector'),\n",
       "  Relation(label='CANNOT OPERATE AT FRAME RATE', source_id='Harris detector', target_id='frame rate', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='frame rate')],\n",
       " [EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'SIFT', 'processing_time': '195%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='SIFT'),\n",
       "  Relation(label='CANNOT OPERATE AT FRAME RATE', source_id='SIFT', target_id='frame rate', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='frame rate')],\n",
       " [EntityNode(label='HEURISTIC', embedding=None, properties={'id': 'new heuristic for feature detection', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='new heuristic for feature detection'),\n",
       "  Relation(label='PRESENTED', source_id='new heuristic for feature detection', target_id='live PAL video processing', properties={'purpose': 'live PAL video processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='APPLICATION', embedding=None, properties={'id': 'live PAL video processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='live PAL video processing')],\n",
       " [EntityNode(label='TECHNIQUE', embedding=None, properties={'id': 'machine learning', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='machine learning'),\n",
       "  Relation(label='DERIVES', source_id='machine learning', target_id='feature detector', properties={'derivative': 'feature detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='DETECTOR', embedding=None, properties={'id': 'feature detector', 'processing_time': '< 5%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='feature detector')],\n",
       " [EntityNode(label='CORNER_DETECTOR_PROPERTIES', embedding=None, properties={'id': 'efficiency', 'importance': 'operate at frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='efficiency'),\n",
       "  Relation(label='AFFECTS', source_id='efficiency', target_id='ability to operate at frame rate', properties={'impact': 'combined with further processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'ability to operate at frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='ability to operate at frame rate')],\n",
       " [EntityNode(label='CORNER_DETECTOR_FEATURE', embedding=None, properties={'id': 'optimization for repeatability', 'optimization_type': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='optimization for repeatability'),\n",
       "  Relation(label='ALLOWED', source_id='optimization for repeatability', target_id='corner detector', properties={'loss': 'little', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'corner detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='corner detector')],\n",
       " [EntityNode(label='SCENE', embedding=None, properties={'id': '3D scenes', 'dimension': '3D', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='3D scenes'),\n",
       "  Relation(label='USED FOR', source_id='3D scenes', target_id='comparison of corner detectors', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='COMPARISON', embedding=None, properties={'id': 'comparison of corner detectors', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='comparison of corner detectors')],\n",
       " [EntityNode(label='DETECTOR', embedding=None, properties={'id': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='our heuristic detector'),\n",
       "  Relation(label='OUTPERFORMS', source_id='our heuristic detector', target_id='existing feature detectors', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd', 'existing_detectors': True}),\n",
       "  EntityNode(label='FEATURE_DETECTOR', embedding=None, properties={'id': 'existing feature detectors', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='existing feature detectors')],\n",
       " [EntityNode(label='TESTS', embedding=None, properties={'id': 'stringent tests', 'criterion': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='stringent tests'),\n",
       "  Relation(label='APPLIED TO', source_id='stringent tests', target_id='3D scenes', properties={'scene': '3D scenes', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='SCENE', embedding=None, properties={'id': '3D scenes', 'dimension': '3D', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='3D scenes')],\n",
       " [EntityNode(label='TECHNIQUE_USE', embedding=None, properties={'id': 'using machine learning', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='using machine learning'),\n",
       "  Relation(label='PRODUCES', source_id='using machine learning', target_id='significant improvements in repeatability', properties={'improvement': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='IMPROVEMENT', embedding=None, properties={'id': 'significant improvements in repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='significant improvements in repeatability')],\n",
       " [EntityNode(label='DETECTOR', embedding=None, properties={'id': 'very fast and very high quality', 'speed': 'fast', 'quality': 'high', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='very fast and very high quality'),\n",
       "  Relation(label='RESULTS IN', source_id='very fast and very high quality', target_id='our heuristic detector', properties={'detector': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='DETECTOR', embedding=None, properties={'id': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='our heuristic detector')],\n",
       " [EntityNode(label='PROFESSION', embedding=None, properties={'id': 'AI researchers', 'argues': ['analogy is the core of cognition'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='AI researchers'),\n",
       "  Relation(label='ARGUE', source_id='AI researchers', target_id='analogy', properties={'about': ['the core of cognition'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='CONCEPT', embedding=None, properties={'id': 'analogy', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='analogy')],\n",
       " [EntityNode(label='THEORY', embedding=None, properties={'id': 'Structure Mapping Theory (SMT)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Theory (SMT)'),\n",
       "  Relation(label='IMPLEMENTED', source_id='Structure Mapping Theory (SMT)', target_id='Structure Mapping Engine (SME)', properties={'in': ['the Structure Mapping Engine (SME)'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Structure Mapping Engine (SME)', 'limitation': ['requirement for complex hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Engine (SME)')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Structure Mapping Engine (SME)', 'limitation': ['requirement for complex hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Engine (SME)'),\n",
       "  Relation(label='INTRODUCED', source_id='Structure Mapping Engine (SME)', target_id='Latent Relation Mapping Engine (LRME)', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='COMBINES', source_id='Latent Relation Mapping Engine (LRME)', target_id='SME and LRA', properties={'ideas': ['from SME and Latent Relational Analysis (LRA)'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='CONCEPTS', embedding=None, properties={'id': 'SME and LRA', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='SME and LRA')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='REMOVES_REQUIREMENT', source_id='Latent Relation Mapping Engine (LRME)', target_id='requirement for hand-coded representations', properties={'for': ['hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM_LIMITATION', embedding=None, properties={'id': 'requirement for hand-coded representations', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='requirement for hand-coded representations')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='BUILDs', source_id='Latent Relation Mapping Engine (LRME)', target_id='lists of words', properties={'analogical mappings': ['between lists of words'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'lists of words', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='lists of words')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='USES', source_id='Latent Relation Mapping Engine (LRME)', target_id='raw text', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304', 'a large corpus of raw text': ['to automatically discover the semantic relations among the words']}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'raw text', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='raw text')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='EVALUATED_ON', source_id='Latent Relation Mapping Engine (LRME)', target_id='twenty analogical mapping problems', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'twenty analogical mapping problems', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='twenty analogical mapping problems')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='ACHIEVES', source_id='Latent Relation Mapping Engine (LRME)', target_id='human-level performance', properties={'human-level performance': ['on the twenty problems'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='PERFORMANCE_LEVEL', embedding=None, properties={'id': 'human-level performance', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='human-level performance')],\n",
       " [EntityNode(label='APPROACH', embedding=None, properties={'id': 'Various alternative approaches', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Various alternative approaches'),\n",
       "  Relation(label='COMPARED_WITH', source_id='Various alternative approaches', target_id='LRME', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'LRME', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='LRME')],\n",
       " [EntityNode(label='APPROACH', embedding=None, properties={'id': 'Various alternative approaches', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Various alternative approaches'),\n",
       "  Relation(label='NOT_ABLE', source_id='Various alternative approaches', target_id='same level of performance', properties={'to reach the same level of performance': ['as LRME'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='PERFORMANCE_LEVEL', embedding=None, properties={'id': 'same level of performance', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='same level of performance')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can automate reasoning in and about', source_id='LEO-II', target_id='monomodal logics K and S4', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='LOGIC', embedding=None, properties={'id': 'monomodal logics K and S4', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='monomodal logics K and S4')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can also automate reasoning in and about', source_id='LEO-II', target_id='different access control logics', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'different access control logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='different access control logics')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can be applied to automate reasoning in', source_id='LEO-II', target_id='prominent access control logics', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'prominent access control logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='prominent access control logics')],\n",
       " [EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'Different Access Control Logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='Different Access Control Logics'),\n",
       "  Relation(label='can be embedded in', source_id='Different Access Control Logics', target_id='Simple Type Theory', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='LOGIC', embedding=None, properties={'id': 'Simple Type Theory', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='Simple Type Theory')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Has Vertices', source_id='Semantic Network', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Vertices are fundamental components of Semantic Networks.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Contains Edges', source_id='Semantic Network', target_id='Edge', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Edges define relationships between vertices in a Semantic Network.'}),\n",
       "  EntityNode(label='Connection between Vertices', embedding=None, properties={'id': 'Edge', 'entity_description': 'Represents the relationship between two vertices in a semantic network and can qualify this relationship with specific meanings or weights.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Edge')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Important for Centrality', source_id='Semantic Network', target_id='Central Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Central Vertices hold significant importance within the network based on context-based rankings.'}),\n",
       "  EntityNode(label='Node within the Network', embedding=None, properties={'id': 'Central Vertex', 'entity_description': 'A vertex that holds significant importance due to its centrality within the network, often determined by context-based metrics.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Central Vertex')],\n",
       " [EntityNode(label='Algorithm or Methodology', embedding=None, properties={'id': 'Context-Based Ranking', 'entity_description': 'A ranking system based on user-defined contexts to determine the relevance of vertices in a semantic network.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Context-Based Ranking'),\n",
       "  Relation(label='Determines Relevance', source_id='Context-Based Ranking', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Context-Based Rankings help determine the relevance of vertices in semantic networks.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Directed Path between Vertices', embedding=None, properties={'id': 'Semantic Association', 'entity_description': 'Paths or connections between vertices that carry semantic meaning, often representing relationships or interactions within the network.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Association'),\n",
       "  Relation(label='Defined by Edges', source_id='Semantic Association', target_id='Edge', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Semantic Associations are represented as directed paths between vertices, defined by edges.'}),\n",
       "  EntityNode(label='Connection between Vertices', embedding=None, properties={'id': 'Edge', 'entity_description': 'Represents the relationship between two vertices in a semantic network and can qualify this relationship with specific meanings or weights.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Edge')],\n",
       " [EntityNode(label='Ranking Metric', embedding=None, properties={'id': 'Eigenvector Centrality', 'entity_description': 'A centrality metric based on eigenvectors of a matrix associated with the graph, used to rank vertices in semantic networks.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Eigenvector Centrality'),\n",
       "  Relation(label='Ranks Vertices Based on Eigenvectors', source_id='Eigenvector Centrality', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Eigenvector Centrality ranks vertices based on the eigenvector centrality metric.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Ranking Metric', embedding=None, properties={'id': 'PageRank', 'entity_description': 'Another type of ranking metric often used for web page importance but adapted here for use in semantic network analysis.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='PageRank'),\n",
       "  Relation(label='Ranks Vertices Based on Links', source_id='PageRank', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'PageRank ranks vertices based on link analysis, similar to web pages in a network.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Analysis Framework', embedding=None, properties={'id': 'Random Walker Model', 'entity_description': 'A model used to simulate random navigation through a graph, with modifications allowing for grammar-based constraints that define the meaning of vertex rankings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Random Walker Model'),\n",
       "  Relation(label='Navigates Vertices', source_id='Random Walker Model', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'The Random Walker model simulates navigation through the graph, visiting vertices according to certain rules or probabilities.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='User-Defined Data Structure', embedding=None, properties={'id': 'Grammar', 'entity_description': 'A set of rules or patterns defined by users to guide the random walking process and influence the final ranking of vertices based on semantic meanings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Grammar'),\n",
       "  Relation(label='Guides Navigation', source_id='Grammar', target_id='Random Walker Model', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'A Grammar guides and constrains random walking in the model, defining the meaning of paths taken by walkers.'}),\n",
       "  EntityNode(label='Analysis Framework', embedding=None, properties={'id': 'Random Walker Model', 'entity_description': 'A model used to simulate random navigation through a graph, with modifications allowing for grammar-based constraints that define the meaning of vertex rankings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Random Walker Model')],\n",
       " [EntityNode(label='Standard for Semantic Web Data', embedding=None, properties={'id': 'RDF', 'entity_description': 'A standard for describing resources in a way that can be read by both humans and machines, used to structure the data within semantic networks.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='RDF'),\n",
       "  Relation(label='Used to Structure Data', source_id='RDF', target_id='Semantic Network', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'RDF is used to structure data within semantic networks, providing a standard for describing resources.'}),\n",
       "  EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network')],\n",
       " [EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector'),\n",
       "  Relation(label='uses', source_id='Corner Detector', target_id='Feature Detection Heuristic', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'The feature detection heuristic is used to develop a new corner detector algorithm.'}),\n",
       "  EntityNode(label='Methodology', embedding=None, properties={'id': 'Feature Detection Heuristic', 'entity_description': 'A new heuristic method developed as part of the research to enhance feature detection processes.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Feature Detection Heuristic')],\n",
       " [EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector'),\n",
       "  Relation(label='requires', source_id='Corner Detector', target_id='Repeatability', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Repeatability is a critical property of corner detectors, ensuring consistent results across different viewing positions.'}),\n",
       "  EntityNode(label='Property', embedding=None, properties={'id': 'Repeatability', 'entity_description': 'The quality of yielding consistent results when the same scene is viewed from different positions, indicating the robustness and reliability of the corner detector.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Repeatability')],\n",
       " [EntityNode(label='Technology', embedding=None, properties={'id': 'Machine Learning Technique', 'entity_description': 'The application of machine learning methods to derive a feature detector from the proposed heuristic.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Machine Learning Technique'),\n",
       "  Relation(label='applies', source_id='Machine Learning Technique', target_id='Feature Detection Heuristic', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Machine learning techniques are applied to the feature detection heuristic to derive an efficient detector.'}),\n",
       "  EntityNode(label='Methodology', embedding=None, properties={'id': 'Feature Detection Heuristic', 'entity_description': 'A new heuristic method developed as part of the research to enhance feature detection processes.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Feature Detection Heuristic')],\n",
       " [EntityNode(label='Technology', embedding=None, properties={'id': 'Machine Learning Technique', 'entity_description': 'The application of machine learning methods to derive a feature detector from the proposed heuristic.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Machine Learning Technique'),\n",
       "  Relation(label='optimizes', source_id='Machine Learning Technique', target_id='Processing Time', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'The machine learning technique is applied to optimize processing time, reducing it significantly compared to other methods.'}),\n",
       "  EntityNode(label='Metric', embedding=None, properties={'id': 'Processing Time', 'entity_description': 'The amount of time required to process live video using the detector, measured in percentage terms relative to available processing resources.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Processing Time')],\n",
       " [EntityNode(label='Property', embedding=None, properties={'id': 'Efficiency', 'entity_description': 'The ability to process data quickly without excessive computational overhead.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Efficiency'),\n",
       "  Relation(label='measures', source_id='Efficiency', target_id='Corner Detector', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': \"Efficiency is evaluated by the detector's ability to operate at frame rate with minimal processing time.\"}),\n",
       "  EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector')],\n",
       " [EntityNode(label='Existing Algorithm', embedding=None, properties={'id': 'Harris Detector', 'entity_description': 'A well-known corner detection algorithm used as a baseline for comparison in the paper.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Harris Detector'),\n",
       "  Relation(label='compares against', source_id='Harris Detector', target_id='SIFT', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Both Harris Detector and SIFT are used as baselines for comparison in evaluating new corner detectors.'}),\n",
       "  EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'SIFT', 'processing_time': '195%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='SIFT')],\n",
       " [EntityNode(label='Data Type', embedding=None, properties={'id': 'Live PAL Video', 'entity_description': 'The type of video input used to evaluate the performance of the corner detector in real-time scenarios.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Live PAL Video'),\n",
       "  Relation(label='input', source_id='Live PAL Video', target_id='Corner Detector', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Live PAL video is the input type used to test the performance of the detector.'}),\n",
       "  EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector')],\n",
       " [EntityNode(label='Input', embedding=None, properties={'id': '3D Scene', 'entity_description': 'A computer-generated or captured three-dimensional scene used as an input for testing repeatability criteria.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='3D Scene'),\n",
       "  Relation(label='evaluates', source_id='3D Scene', target_id='Repeatability', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': '3D scenes are used as inputs for rigorous repeatability testing criteria.'}),\n",
       "  EntityNode(label='Property', embedding=None, properties={'id': 'Repeatability', 'entity_description': 'The quality of yielding consistent results when the same scene is viewed from different positions, indicating the robustness and reliability of the corner detector.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Repeatability')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='DEFINED_ON', source_id='Graphical Model', target_id='arbitrary graphical model', properties={'type': 'graph', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'arbitrary graphical model', 'type': 'arbitrary', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='arbitrary graphical model')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='SOLVED_EXACTLY_AND_EFFICIENTLY', source_id='Graphical Model', target_id='tree (graph without loops)', properties={'method': 'BP algorithm', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='GRAPHICAL_STRUCTURE', embedding=None, properties={'id': 'tree (graph without loops)', 'type': 'tree', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='tree (graph without loops)')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='MAY_SHOW_MULTIPLE_MINIMA', source_id='Graphical Model', target_id='Bethe free energy functional', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='FUNCTIONAL', embedding=None, properties={'id': 'Bethe free energy functional', 'type': 'Bethe', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Bethe free energy functional')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='MAY_CONVERGE_INCOMPLETELY', source_id='Graphical Model', target_id='zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='TEMPERATURE_STATE', embedding=None, properties={'id': 'zero-temperature limit', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature limit')],\n",
       " [EntityNode(label='ALGORITHM', embedding=None, properties={'id': 'g-BP Algorithm', 'type': 'gedanken', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP Algorithm'),\n",
       "  Relation(label='FUNDS', source_id='g-BP Algorithm', target_id='zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='TEMPERATURE_STATE', embedding=None, properties={'id': 'zero-temperature limit', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature limit')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='DOES_NOT_GUARANTEE_GLOBAL_MINIMUM', source_id='Graphical Model', target_id='ML solution in the zero-temperature limit', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='SOLUTION', embedding=None, properties={'id': 'ML solution in the zero-temperature limit', 'type': 'Maximum-Likelihood', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='ML solution in the zero-temperature limit')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='HAS_EXCEPTIONS', source_id='Graphical Model', target_id='zero-temperature version of the BP algorithm finds ML solution', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='EXCEPTION', embedding=None, properties={'id': 'zero-temperature version of the BP algorithm finds ML solution', 'type': 'finds', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='zero-temperature version of the BP algorithm finds ML solution')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='SHARES_KEY_FEATURE', source_id='Graphical Model', target_id='two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='MODEL', embedding=None, properties={'id': 'two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E', 'reference': ['<cite>05KW</cite>', '<cite>08BSS</cite>'], 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='two models discussed in \\\\u003Ccite\\\\u003E05KW\\\\u003C/cite\\\\u003E and \\\\u003Ccite\\\\u003E08BSS\\\\u003C/cite\\\\u003E')],\n",
       " [EntityNode(label='STATISTICAL_MODEL', embedding=None, properties={'id': 'Graphical Model', 'type': 'reducible LP with TUM constraints', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='Graphical Model'),\n",
       "  Relation(label='CONSIDERED', source_id='Graphical Model', target_id='g-BP algorithm', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='ALGORITHM', embedding=None, properties={'id': 'g-BP algorithm', 'type': 'gedanken', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP algorithm')],\n",
       " [EntityNode(label='OUTPUT', embedding=None, properties={'id': 'g-BP Algorithm output', 'type': 'solution', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='g-BP Algorithm output'),\n",
       "  Relation(label='EQUALS', source_id='g-BP Algorithm output', target_id='limit of zero temperature', properties={'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}),\n",
       "  EntityNode(label='LIMIT', embedding=None, properties={'id': 'limit of zero temperature', 'type': 'zero', 'triplet_source_id': 'b2f2dda2-a5e4-4cc9-ae08-a977488d1db4'}, name='limit of zero temperature')],\n",
       " [EntityNode(label='RESEARCH_TOPIC', embedding=None, properties={'id': 'Grammar-Based Random Walkers', 'prop1': 'area of study', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Grammar-Based Random Walkers'),\n",
       "  Relation(label='APPLIES_TO', source_id='Grammar-Based Random Walkers', target_id='Semantic Networks', properties={'prop1': 'context', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='NETWORK', embedding=None, properties={'id': 'Semantic Networks', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Semantic Networks')],\n",
       " [EntityNode(label='NETWORK', embedding=None, properties={'id': 'Semantic networks', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Semantic networks'),\n",
       "  Relation(label='QUALIFIES_MEANING_OF', source_id='Semantic networks', target_id='edge', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='EDGE', embedding=None, properties={'id': 'edge', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='edge')],\n",
       " [EntityNode(label='EDGE', embedding=None, properties={'id': 'edge', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='edge'),\n",
       "  Relation(label='RELATES', source_id='edge', target_id='two vertices', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='VERTEX', embedding=None, properties={'id': 'two vertices', 'prop1': 'number', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='two vertices')],\n",
       " [EntityNode(label='QUESTION', embedding=None, properties={'id': 'which vertices are most  central ', 'prop1': 'question', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='which vertices are most \"central\"'),\n",
       "  Relation(label='IS_DIFFICULT_TO_DETERMINE', source_id='which vertices are most \"central\"', target_id='in a semantic network', properties={'prop1': 'state', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='NETWORK', embedding=None, properties={'id': 'in a semantic network', 'prop1': 'domain', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='in a semantic network')],\n",
       " [EntityNode(label='RELATIONSHIP', embedding=None, properties={'id': 'one relationship type', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='one relationship type'),\n",
       "  Relation(label='MAY_BE_DEEMED', source_id='one relationship type', target_id='subjectively more important', properties={'prop1': 'state', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='STATE', embedding=None, properties={'id': 'subjectively more important', 'prop1': 'description', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='subjectively more important')],\n",
       " [EntityNode(label='RESEARCH', embedding=None, properties={'id': 'research into semantic network metrics', 'prop1': 'focus', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='research into semantic network metrics'),\n",
       "  Relation(label='HAS_FOCUSED_PRIMARILY_ON', source_id='research into semantic network metrics', target_id='context-based rankings', properties={'prop1': 'area', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='RANKING', embedding=None, properties={'id': 'context-based rankings', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='context-based rankings')],\n",
       " [EntityNode(label='RANKING', embedding=None, properties={'id': 'context-based rankings', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='context-based rankings'),\n",
       "  Relation(label='I.E.', source_id='context-based rankings', target_id='user prescribed contexts', properties={'prop1': 'represents', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='CONTEXT', embedding=None, properties={'id': 'user prescribed contexts', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='user prescribed contexts')],\n",
       " [EntityNode(label='METRIC', embedding=None, properties={'id': 'many of the current semantic network metrics', 'prop1': 'category', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='many of the current semantic network metrics'),\n",
       "  Relation(label='RANK', source_id='many of the current semantic network metrics', target_id='semantic associations', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='ASSOCIATION', embedding=None, properties={'id': 'semantic associations', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='semantic associations')],\n",
       " [EntityNode(label='ASSOCIATION', embedding=None, properties={'id': 'semantic associations', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='semantic associations'),\n",
       "  Relation(label='REPRESENTED_BY', source_id='semantic associations', target_id='directed paths between two vertices', properties={'prop1': 'represents', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='PATH', embedding=None, properties={'id': 'directed paths between two vertices', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='directed paths between two vertices')],\n",
       " [EntityNode(label='CONCEPT', embedding=None, properties={'id': 'Random walkers, in the context of this article', 'prop1': 'context', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Random walkers, in the context of this article'),\n",
       "  Relation(label='ARE_CONSTRAINED_BY', source_id='Random walkers, in the context of this article', target_id='a grammar', properties={'prop1': 'condition', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='DATA_STRUCTURE', embedding=None, properties={'id': 'a grammar', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='a grammar')],\n",
       " [EntityNode(label='DATA_STRUCTURE', embedding=None, properties={'id': 'a grammar', 'prop1': 'type', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='a grammar'),\n",
       "  Relation(label='DETERMINES_THE', source_id='a grammar', target_id='meaning of the final vertex ranking', properties={'prop1': 'action', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='RANKING', embedding=None, properties={'id': 'meaning of the final vertex ranking', 'prop1': 'output', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='meaning of the final vertex ranking')],\n",
       " [EntityNode(label='STANDARD', embedding=None, properties={'id': 'Resource Description Framework (RDF)', 'prop1': 'name', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='Resource Description Framework (RDF)'),\n",
       "  Relation(label='OF', source_id='Resource Description Framework (RDF)', target_id='the Semantic Web initiative', properties={'prop1': 'connection', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}),\n",
       "  EntityNode(label='INITIATIVE', embedding=None, properties={'id': 'the Semantic Web initiative', 'prop1': 'group', 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}, name='the Semantic Web initiative')],\n",
       " [EntityNode(label='ARTICLE_TITLE', embedding=None, properties={'id': 'Faster and better', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Faster and better'),\n",
       "  Relation(label='DISCUSSES', source_id='Faster and better', target_id='machine learning approach to corner detection', properties={'discussion_topic': ['machine learning approach to corner detection'], 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='RESEARCH_TOPIC', embedding=None, properties={'id': 'machine learning approach to corner detection', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='machine learning approach to corner detection')],\n",
       " [EntityNode(label='CORNER_DETECTOR_PROPERTIES', embedding=None, properties={'id': 'repeatability and efficiency', 'importance': 'real-world application', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='repeatability and efficiency'),\n",
       "  Relation(label='AFFECTS', source_id='repeatability and efficiency', target_id='usefulness of a corner detector', properties={'impact': 'usefulness', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='UTILITY', embedding=None, properties={'id': 'usefulness of a corner detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='usefulness of a corner detector')],\n",
       " [EntityNode(label='SCENE', embedding=None, properties={'id': 'same scene viewed from different positions', 'viewing_position': 'different', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='same scene viewed from different positions'),\n",
       "  Relation(label='SHOULD YIELD', source_id='same scene viewed from different positions', target_id='features which correspond to the same real-world 3D locations', properties={'correspondence': 'real-world 3D locations', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='FEATURES', embedding=None, properties={'id': 'features which correspond to the same real-world 3D locations', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='features which correspond to the same real-world 3D locations')],\n",
       " [EntityNode(label='REFERENCE', embedding=None, properties={'id': 'Schmid et al 2000', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Schmid et al 2000'),\n",
       "  Relation(label='CITES', source_id='Schmid et al 2000', target_id='repeatability criterion', properties={'work': 'repeatability criterion', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='CRITERION', embedding=None, properties={'id': 'repeatability criterion', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='repeatability criterion')],\n",
       " [EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'Harris detector', 'processing_time': '115%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='Harris detector'),\n",
       "  Relation(label='CANNOT OPERATE AT FRAME RATE', source_id='Harris detector', target_id='frame rate', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='frame rate')],\n",
       " [EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'SIFT', 'processing_time': '195%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='SIFT'),\n",
       "  Relation(label='CANNOT OPERATE AT FRAME RATE', source_id='SIFT', target_id='frame rate', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='frame rate')],\n",
       " [EntityNode(label='Existing Algorithm', embedding=None, properties={'id': 'Harris Detector', 'entity_description': 'A well-known corner detection algorithm used as a baseline for comparison in the paper.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Harris Detector'),\n",
       "  Relation(label='compares against', source_id='Harris Detector', target_id='SIFT', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Both Harris Detector and SIFT are used as baselines for comparison in evaluating new corner detectors.'}),\n",
       "  EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'SIFT', 'processing_time': '195%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='SIFT')],\n",
       " [EntityNode(label='HEURISTIC', embedding=None, properties={'id': 'new heuristic for feature detection', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='new heuristic for feature detection'),\n",
       "  Relation(label='PRESENTED', source_id='new heuristic for feature detection', target_id='live PAL video processing', properties={'purpose': 'live PAL video processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='APPLICATION', embedding=None, properties={'id': 'live PAL video processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='live PAL video processing')],\n",
       " [EntityNode(label='TECHNIQUE', embedding=None, properties={'id': 'machine learning', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='machine learning'),\n",
       "  Relation(label='DERIVES', source_id='machine learning', target_id='feature detector', properties={'derivative': 'feature detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='DETECTOR', embedding=None, properties={'id': 'feature detector', 'processing_time': '< 5%', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='feature detector')],\n",
       " [EntityNode(label='CORNER_DETECTOR_PROPERTIES', embedding=None, properties={'id': 'efficiency', 'importance': 'operate at frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='efficiency'),\n",
       "  Relation(label='AFFECTS', source_id='efficiency', target_id='ability to operate at frame rate', properties={'impact': 'combined with further processing', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='OPERATIONAL_SPEED', embedding=None, properties={'id': 'ability to operate at frame rate', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='ability to operate at frame rate')],\n",
       " [EntityNode(label='CORNER_DETECTOR_FEATURE', embedding=None, properties={'id': 'optimization for repeatability', 'optimization_type': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='optimization for repeatability'),\n",
       "  Relation(label='ALLOWED', source_id='optimization for repeatability', target_id='corner detector', properties={'loss': 'little', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='CORNER_DETECTOR', embedding=None, properties={'id': 'corner detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='corner detector')],\n",
       " [EntityNode(label='TESTS', embedding=None, properties={'id': 'stringent tests', 'criterion': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='stringent tests'),\n",
       "  Relation(label='APPLIED TO', source_id='stringent tests', target_id='3D scenes', properties={'scene': '3D scenes', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='SCENE', embedding=None, properties={'id': '3D scenes', 'dimension': '3D', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='3D scenes')],\n",
       " [EntityNode(label='SCENE', embedding=None, properties={'id': '3D scenes', 'dimension': '3D', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='3D scenes'),\n",
       "  Relation(label='USED FOR', source_id='3D scenes', target_id='comparison of corner detectors', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='COMPARISON', embedding=None, properties={'id': 'comparison of corner detectors', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='comparison of corner detectors')],\n",
       " [EntityNode(label='DETECTOR', embedding=None, properties={'id': 'very fast and very high quality', 'speed': 'fast', 'quality': 'high', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='very fast and very high quality'),\n",
       "  Relation(label='RESULTS IN', source_id='very fast and very high quality', target_id='our heuristic detector', properties={'detector': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='DETECTOR', embedding=None, properties={'id': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='our heuristic detector')],\n",
       " [EntityNode(label='DETECTOR', embedding=None, properties={'id': 'our heuristic detector', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='our heuristic detector'),\n",
       "  Relation(label='OUTPERFORMS', source_id='our heuristic detector', target_id='existing feature detectors', properties={'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd', 'existing_detectors': True}),\n",
       "  EntityNode(label='FEATURE_DETECTOR', embedding=None, properties={'id': 'existing feature detectors', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='existing feature detectors')],\n",
       " [EntityNode(label='TECHNIQUE_USE', embedding=None, properties={'id': 'using machine learning', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='using machine learning'),\n",
       "  Relation(label='PRODUCES', source_id='using machine learning', target_id='significant improvements in repeatability', properties={'improvement': 'repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}),\n",
       "  EntityNode(label='IMPROVEMENT', embedding=None, properties={'id': 'significant improvements in repeatability', 'triplet_source_id': '1198ae08-be4e-4c1d-811b-06b1c213f7cd'}, name='significant improvements in repeatability')],\n",
       " [EntityNode(label='PROFESSION', embedding=None, properties={'id': 'AI researchers', 'argues': ['analogy is the core of cognition'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='AI researchers'),\n",
       "  Relation(label='ARGUE', source_id='AI researchers', target_id='analogy', properties={'about': ['the core of cognition'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='CONCEPT', embedding=None, properties={'id': 'analogy', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='analogy')],\n",
       " [EntityNode(label='THEORY', embedding=None, properties={'id': 'Structure Mapping Theory (SMT)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Theory (SMT)'),\n",
       "  Relation(label='IMPLEMENTED', source_id='Structure Mapping Theory (SMT)', target_id='Structure Mapping Engine (SME)', properties={'in': ['the Structure Mapping Engine (SME)'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Structure Mapping Engine (SME)', 'limitation': ['requirement for complex hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Engine (SME)')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Structure Mapping Engine (SME)', 'limitation': ['requirement for complex hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Structure Mapping Engine (SME)'),\n",
       "  Relation(label='INTRODUCED', source_id='Structure Mapping Engine (SME)', target_id='Latent Relation Mapping Engine (LRME)', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='COMBINES', source_id='Latent Relation Mapping Engine (LRME)', target_id='SME and LRA', properties={'ideas': ['from SME and Latent Relational Analysis (LRA)'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='CONCEPTS', embedding=None, properties={'id': 'SME and LRA', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='SME and LRA')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='REMOVES_REQUIREMENT', source_id='Latent Relation Mapping Engine (LRME)', target_id='requirement for hand-coded representations', properties={'for': ['hand-coded representations'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM_LIMITATION', embedding=None, properties={'id': 'requirement for hand-coded representations', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='requirement for hand-coded representations')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='BUILDs', source_id='Latent Relation Mapping Engine (LRME)', target_id='lists of words', properties={'analogical mappings': ['between lists of words'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'lists of words', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='lists of words')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='USES', source_id='Latent Relation Mapping Engine (LRME)', target_id='raw text', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304', 'a large corpus of raw text': ['to automatically discover the semantic relations among the words']}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'raw text', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='raw text')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='EVALUATED_ON', source_id='Latent Relation Mapping Engine (LRME)', target_id='twenty analogical mapping problems', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='DATASET', embedding=None, properties={'id': 'twenty analogical mapping problems', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='twenty analogical mapping problems')],\n",
       " [EntityNode(label='SYSTEM', embedding=None, properties={'id': 'Latent Relation Mapping Engine (LRME)', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Latent Relation Mapping Engine (LRME)'),\n",
       "  Relation(label='ACHIEVES', source_id='Latent Relation Mapping Engine (LRME)', target_id='human-level performance', properties={'human-level performance': ['on the twenty problems'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='PERFORMANCE_LEVEL', embedding=None, properties={'id': 'human-level performance', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='human-level performance')],\n",
       " [EntityNode(label='APPROACH', embedding=None, properties={'id': 'Various alternative approaches', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Various alternative approaches'),\n",
       "  Relation(label='COMPARED_WITH', source_id='Various alternative approaches', target_id='LRME', properties={'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='SYSTEM', embedding=None, properties={'id': 'LRME', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='LRME')],\n",
       " [EntityNode(label='APPROACH', embedding=None, properties={'id': 'Various alternative approaches', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='Various alternative approaches'),\n",
       "  Relation(label='NOT_ABLE', source_id='Various alternative approaches', target_id='same level of performance', properties={'to reach the same level of performance': ['as LRME'], 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}),\n",
       "  EntityNode(label='PERFORMANCE_LEVEL', embedding=None, properties={'id': 'same level of performance', 'triplet_source_id': '832af341-594b-451c-8a36-e55b4e76e304'}, name='same level of performance')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can automate reasoning in and about', source_id='LEO-II', target_id='monomodal logics K and S4', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='LOGIC', embedding=None, properties={'id': 'monomodal logics K and S4', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='monomodal logics K and S4')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can also automate reasoning in and about', source_id='LEO-II', target_id='different access control logics', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'different access control logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='different access control logics')],\n",
       " [EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'Different Access Control Logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='Different Access Control Logics'),\n",
       "  Relation(label='can be embedded in', source_id='Different Access Control Logics', target_id='Simple Type Theory', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='LOGIC', embedding=None, properties={'id': 'Simple Type Theory', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='Simple Type Theory')],\n",
       " [EntityNode(label='TOOL', embedding=None, properties={'id': 'LEO-II', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='LEO-II'),\n",
       "  Relation(label='can be applied to automate reasoning in', source_id='LEO-II', target_id='prominent access control logics', properties={'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}),\n",
       "  EntityNode(label='ACCESS_CONTROL_LOGIC', embedding=None, properties={'id': 'prominent access control logics', 'triplet_source_id': 'f7d9b6e4-c572-4110-b73a-8b5765a533ba'}, name='prominent access control logics')],\n",
       " [EntityNode(label='Standard for Semantic Web Data', embedding=None, properties={'id': 'RDF', 'entity_description': 'A standard for describing resources in a way that can be read by both humans and machines, used to structure the data within semantic networks.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='RDF'),\n",
       "  Relation(label='Used to Structure Data', source_id='RDF', target_id='Semantic Network', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'RDF is used to structure data within semantic networks, providing a standard for describing resources.'}),\n",
       "  EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Has Vertices', source_id='Semantic Network', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Vertices are fundamental components of Semantic Networks.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Algorithm or Methodology', embedding=None, properties={'id': 'Context-Based Ranking', 'entity_description': 'A ranking system based on user-defined contexts to determine the relevance of vertices in a semantic network.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Context-Based Ranking'),\n",
       "  Relation(label='Determines Relevance', source_id='Context-Based Ranking', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Context-Based Rankings help determine the relevance of vertices in semantic networks.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Ranking Metric', embedding=None, properties={'id': 'Eigenvector Centrality', 'entity_description': 'A centrality metric based on eigenvectors of a matrix associated with the graph, used to rank vertices in semantic networks.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Eigenvector Centrality'),\n",
       "  Relation(label='Ranks Vertices Based on Eigenvectors', source_id='Eigenvector Centrality', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Eigenvector Centrality ranks vertices based on the eigenvector centrality metric.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Ranking Metric', embedding=None, properties={'id': 'PageRank', 'entity_description': 'Another type of ranking metric often used for web page importance but adapted here for use in semantic network analysis.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='PageRank'),\n",
       "  Relation(label='Ranks Vertices Based on Links', source_id='PageRank', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'PageRank ranks vertices based on link analysis, similar to web pages in a network.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Analysis Framework', embedding=None, properties={'id': 'Random Walker Model', 'entity_description': 'A model used to simulate random navigation through a graph, with modifications allowing for grammar-based constraints that define the meaning of vertex rankings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Random Walker Model'),\n",
       "  Relation(label='Navigates Vertices', source_id='Random Walker Model', target_id='Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'The Random Walker model simulates navigation through the graph, visiting vertices according to certain rules or probabilities.'}),\n",
       "  EntityNode(label='Node in a Graph', embedding=None, properties={'id': 'Vertex', 'entity_description': 'Nodes that represent concepts or entities within a semantic network, connected by edges that describe their relationships.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Vertex')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Contains Edges', source_id='Semantic Network', target_id='Edge', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Edges define relationships between vertices in a Semantic Network.'}),\n",
       "  EntityNode(label='Connection between Vertices', embedding=None, properties={'id': 'Edge', 'entity_description': 'Represents the relationship between two vertices in a semantic network and can qualify this relationship with specific meanings or weights.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Edge')],\n",
       " [EntityNode(label='Directed Path between Vertices', embedding=None, properties={'id': 'Semantic Association', 'entity_description': 'Paths or connections between vertices that carry semantic meaning, often representing relationships or interactions within the network.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Association'),\n",
       "  Relation(label='Defined by Edges', source_id='Semantic Association', target_id='Edge', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Semantic Associations are represented as directed paths between vertices, defined by edges.'}),\n",
       "  EntityNode(label='Connection between Vertices', embedding=None, properties={'id': 'Edge', 'entity_description': 'Represents the relationship between two vertices in a semantic network and can qualify this relationship with specific meanings or weights.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Edge')],\n",
       " [EntityNode(label='Conceptual Framework or Data Structure', embedding=None, properties={'id': 'Semantic Network', 'entity_description': 'A network of interconnected concepts where edges qualify the meaning between any two vertices.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Semantic Network'),\n",
       "  Relation(label='Important for Centrality', source_id='Semantic Network', target_id='Central Vertex', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'Central Vertices hold significant importance within the network based on context-based rankings.'}),\n",
       "  EntityNode(label='Node within the Network', embedding=None, properties={'id': 'Central Vertex', 'entity_description': 'A vertex that holds significant importance due to its centrality within the network, often determined by context-based metrics.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Central Vertex')],\n",
       " [EntityNode(label='User-Defined Data Structure', embedding=None, properties={'id': 'Grammar', 'entity_description': 'A set of rules or patterns defined by users to guide the random walking process and influence the final ranking of vertices based on semantic meanings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Grammar'),\n",
       "  Relation(label='Guides Navigation', source_id='Grammar', target_id='Random Walker Model', properties={'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba', 'relationship_description': 'A Grammar guides and constrains random walking in the model, defining the meaning of paths taken by walkers.'}),\n",
       "  EntityNode(label='Analysis Framework', embedding=None, properties={'id': 'Random Walker Model', 'entity_description': 'A model used to simulate random navigation through a graph, with modifications allowing for grammar-based constraints that define the meaning of vertex rankings.', 'triplet_source_id': 'd48aac58-d885-439d-9e97-bfac8d5f08ba'}, name='Random Walker Model')],\n",
       " [EntityNode(label='Property', embedding=None, properties={'id': 'Efficiency', 'entity_description': 'The ability to process data quickly without excessive computational overhead.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Efficiency'),\n",
       "  Relation(label='measures', source_id='Efficiency', target_id='Corner Detector', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': \"Efficiency is evaluated by the detector's ability to operate at frame rate with minimal processing time.\"}),\n",
       "  EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector')],\n",
       " [EntityNode(label='Data Type', embedding=None, properties={'id': 'Live PAL Video', 'entity_description': 'The type of video input used to evaluate the performance of the corner detector in real-time scenarios.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Live PAL Video'),\n",
       "  Relation(label='input', source_id='Live PAL Video', target_id='Corner Detector', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Live PAL video is the input type used to test the performance of the detector.'}),\n",
       "  EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector')],\n",
       " [EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector'),\n",
       "  Relation(label='uses', source_id='Corner Detector', target_id='Feature Detection Heuristic', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'The feature detection heuristic is used to develop a new corner detector algorithm.'}),\n",
       "  EntityNode(label='Methodology', embedding=None, properties={'id': 'Feature Detection Heuristic', 'entity_description': 'A new heuristic method developed as part of the research to enhance feature detection processes.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Feature Detection Heuristic')],\n",
       " [EntityNode(label='Technology', embedding=None, properties={'id': 'Machine Learning Technique', 'entity_description': 'The application of machine learning methods to derive a feature detector from the proposed heuristic.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Machine Learning Technique'),\n",
       "  Relation(label='applies', source_id='Machine Learning Technique', target_id='Feature Detection Heuristic', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Machine learning techniques are applied to the feature detection heuristic to derive an efficient detector.'}),\n",
       "  EntityNode(label='Methodology', embedding=None, properties={'id': 'Feature Detection Heuristic', 'entity_description': 'A new heuristic method developed as part of the research to enhance feature detection processes.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Feature Detection Heuristic')],\n",
       " [EntityNode(label='Software/Algorithm', embedding=None, properties={'id': 'Corner Detector', 'entity_description': 'A software algorithm used for detecting corners in images or videos, important for various computer vision tasks.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Corner Detector'),\n",
       "  Relation(label='requires', source_id='Corner Detector', target_id='Repeatability', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'Repeatability is a critical property of corner detectors, ensuring consistent results across different viewing positions.'}),\n",
       "  EntityNode(label='Property', embedding=None, properties={'id': 'Repeatability', 'entity_description': 'The quality of yielding consistent results when the same scene is viewed from different positions, indicating the robustness and reliability of the corner detector.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Repeatability')],\n",
       " [EntityNode(label='Input', embedding=None, properties={'id': '3D Scene', 'entity_description': 'A computer-generated or captured three-dimensional scene used as an input for testing repeatability criteria.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='3D Scene'),\n",
       "  Relation(label='evaluates', source_id='3D Scene', target_id='Repeatability', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': '3D scenes are used as inputs for rigorous repeatability testing criteria.'}),\n",
       "  EntityNode(label='Property', embedding=None, properties={'id': 'Repeatability', 'entity_description': 'The quality of yielding consistent results when the same scene is viewed from different positions, indicating the robustness and reliability of the corner detector.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Repeatability')],\n",
       " [EntityNode(label='Technology', embedding=None, properties={'id': 'Machine Learning Technique', 'entity_description': 'The application of machine learning methods to derive a feature detector from the proposed heuristic.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Machine Learning Technique'),\n",
       "  Relation(label='optimizes', source_id='Machine Learning Technique', target_id='Processing Time', properties={'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3', 'relationship_description': 'The machine learning technique is applied to optimize processing time, reducing it significantly compared to other methods.'}),\n",
       "  EntityNode(label='Metric', embedding=None, properties={'id': 'Processing Time', 'entity_description': 'The amount of time required to process live video using the detector, measured in percentage terms relative to available processing resources.', 'triplet_source_id': 'ac79cf0a-e12c-4c0f-ba43-1e48fdf62ba3'}, name='Processing Time')]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()\n",
    "\n",
    "# for triplet in index.property_graph_store.get_triplets():\n",
    "#     print(triplet.re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Grammar-Based Random Walkers',\n",
       " 'prop1': 'area of study',\n",
       " 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prop1': 'context',\n",
       " 'triplet_source_id': 'd753649c-ab98-44b9-a6eb-3e91d4bf9dd9'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][1].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build communities\n",
    "\n",
    "This will create communities and summary for each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'relationship_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperty_graph_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_communities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[172], line 38\u001b[0m, in \u001b[0;36mGraphRAGStore.build_communities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_communities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Builds communities from the graph and summarizes them.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     nx_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_nx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     community_hierarchical_clusters \u001b[38;5;241m=\u001b[39m hierarchical_leiden(\n\u001b[1;32m     40\u001b[0m         nx_graph, max_cluster_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_cluster_size\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_info, community_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_community_info(\n\u001b[1;32m     43\u001b[0m         nx_graph, community_hierarchical_clusters\n\u001b[1;32m     44\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[172], line 52\u001b[0m, in \u001b[0;36mGraphRAGStore._create_nx_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m triplets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_triplets()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity1, relation, entity2 \u001b[38;5;129;01min\u001b[39;00m triplets:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrelation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelationship_description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         relation\u001b[38;5;241m.\u001b[39mproperties[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelationship_description\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     nx_graph\u001b[38;5;241m.\u001b[39madd_node(entity1\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'relationship_description'"
     ]
    }
   ],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create QueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store,\n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The document discusses several key business news: FirstEnergy's earnings results, Tram Nguyen's appointment as the Global Head of Strategic and Sustainable Investments at Bank of America, Thomas Christl's hiring by Morgan Stanley to co-head its coverage of consumer and retail clients in Europe alongside Imran Ansari, and the significant impacts of the COVID-19 pandemic on Delta Air Lines and Southwest Airlines, including the suspension and reinstatement of their dividend payouts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are the main news discussed in the document?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The main news in the energy sector is that GE Vernova and Amplus Solar have entered into a Supplier-Client relationship. GE Vernova has been selected by Amplus Solar to provide and install 40 units of its 2.7-132 onshore wind turbines for a 108 MW wind power project. This means that GE Vernova will be supplying the necessary equipment and services for the successful execution of the project."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the main news in energy sector?\")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FAI_FinalProj_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
